{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern recognition CW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with 6 main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "camId : which camera was used to get the shot (1 or 2)\n",
    "filelist: names of the images (with format x_label_camId_index.png)\n",
    "labels: class of the image (which person's image is it?)\n",
    "query_idx: indexes of test set\n",
    "gallery_idx: indexes of test set used for kNN \n",
    "train_idx: indexes of training and validation set\n",
    "\"\"\"   \n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with the feature vectors of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 2048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "features_np = np.array(features) #list of features converted to an array \n",
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1467"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_idxs['labels'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5328, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1],\n",
       "       [    2],\n",
       "       [    3],\n",
       "       ...,\n",
       "       [14094],\n",
       "       [14095],\n",
       "       [14096]], dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['train_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7368+5328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['query_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12696+1400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classification for query set on gallery set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_filename(image_index): \n",
    "    name = str(train_idxs['filelist'][image_index][0][0])\n",
    "    [dc, label, camId, index] = name.split('_')\n",
    "    return label, camId\n",
    "\n",
    "def delete_images(query_image, query_index, gallery_images, gallery_labels):\n",
    "    gallery_names = train_idxs['filelist'][train_idxs['gallery_idx'].flatten()]\n",
    "    query_label, query_camId = extract_info_from_filename(query_index)\n",
    "    new_gallery_images = []\n",
    "    new_gallery_labels = []\n",
    "    for img, name in zip(gallery_images, gallery_names):\n",
    "        [dc, label_g, camId_g, index] = str(name[0][0]).split('_')\n",
    "        if [int(label_g), int(camId_g)] != [int(query_label), int(query_camId)]:\n",
    "            new_gallery_images.append(img)\n",
    "            new_gallery_labels.append(int(label_g))\n",
    "    return new_gallery_images, new_gallery_labels\n",
    "\n",
    "def score_rank(query_label, rank_k, new_gallery_labels):\n",
    "    #print(rank_k)\n",
    "    rank_k_labels = np.array(new_gallery_labels)[rank_k] #extract the labels which are of rank k\n",
    "    return (query_label[0] in rank_k_labels) #return true if query label in rank k, else false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNClassification_deletions(query_image, query_index, gallery_images, gallery_labels, k):\n",
    "    neigh = NearestNeighbors(n_neighbors=k, n_jobs=-1)\n",
    "    new_gallery_images, new_gallery_labels = delete_images(query_image, query_index, gallery_images, gallery_labels)\n",
    "    neigh.fit(new_gallery_images)   #new_gallery_labels)\n",
    "    distances, indices = neigh.kneighbors(query_image, k)\n",
    "    return distances, indices, new_gallery_labels #neigh.score(query_image, query_label), neigh.predict(query_image), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gallery_labels = train_idxs['labels'][train_idxs['gallery_idx'].flatten()]\n",
    "query_labels = train_idxs['labels'][train_idxs['query_idx'].flatten()]\n",
    "\n",
    "query_images = features_np[train_idxs['query_idx'].flatten()]\n",
    "gallery_images = features_np[train_idxs['gallery_idx'].flatten()]\n",
    "\n",
    "def get_accuracy_for_k_ranks(k):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if(index < 101):\n",
    "            if (index % 10 == 0):\n",
    "                print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "\n",
    "            #perform NN Classification and extract top k ranks \n",
    "            dist, rank_k_indices, new_gallery_labels = NNClassification_deletions(query_images[index].reshape(1, 2048), query_index, gallery_images, gallery_labels, k)\n",
    "            #calculate the score (true/false) for top k images and query image recognition\n",
    "            score = score_rank(query_labels[index], rank_k_indices, new_gallery_labels)\n",
    "            #create a list of scores to get overall accuracy later on\n",
    "            list_of_truths.append(score)\n",
    "    \n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['1_022_2_06.png'], dtype='<U14')], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['filelist'][204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98361254, 0.33195475, 0.26549727, ..., 0.02350602, 0.08491972,\n",
       "        0.00514889],\n",
       "       [1.30696166, 0.22219124, 0.62375975, ..., 0.02954952, 0.37348923,\n",
       "        0.05303315],\n",
       "       [0.29322624, 0.55588913, 0.06961903, ..., 0.15892459, 0.21527511,\n",
       "        0.09551907],\n",
       "       ...,\n",
       "       [0.7593497 , 0.24537075, 2.19513273, ..., 0.47061139, 1.35971546,\n",
       "        0.46198806],\n",
       "       [0.48667279, 0.49618778, 0.30824399, ..., 0.04450084, 1.28799629,\n",
       "        0.37683338],\n",
       "       [0.05719076, 0.60635394, 0.58300596, ..., 0.40994745, 1.37061644,\n",
       "        0.55975795]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21,  26,  48,  54,  58,  62,  99, 101, 127, 134, 153, 156, 200,\n",
       "       204, 255, 263, 272, 280, 294, 300], dtype=uint16)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_idxs['query_idx'].flatten()-1)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, False, False]"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [3, 4, 1, 6, 8]  \n",
    "x = 4\n",
    "[False, True, False, False, False]\n",
    "\n",
    "[x == element for element in list1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_labels = train_idxs['labels'][train_idxs['gallery_idx'].flatten()-1]\n",
    "query_labels = train_idxs['labels'][train_idxs['query_idx'].flatten()-1]\n",
    "\n",
    "query_images = features_np[train_idxs['query_idx'].flatten()-1]\n",
    "gallery_images = features_np[train_idxs['gallery_idx'].flatten()-1]\n",
    "\n",
    "N=100\n",
    "\n",
    "\n",
    "def remove_indices(n_indices, query_index):\n",
    "    query_label, query_camId = extract_info_from_filename(query_index)\n",
    "    n_names = train_idxs['filelist'][n_indices]\n",
    "    #k_images = features_np[k_indices]\n",
    "    #print(k_names.shape, k_names[0], k_images[0])\n",
    "    final_n_indices = []\n",
    "    final_n_labels = []\n",
    "    for index, name in zip(n_indices, n_names):\n",
    "        [dc, label_g, camId_g, index_g] = str(name[0][0]).split('_')\n",
    "        #print(str(name[0][0]).split('_'))\n",
    "        #print(index)\n",
    "        if [int(label_g), int(camId_g)] != [int(query_label), int(query_camId)]:\n",
    "            final_n_indices.append(index)\n",
    "            final_n_labels.append(int(label_g))\n",
    "    return final_n_indices, final_n_labels\n",
    "\n",
    "def calcAP(trueLabel, rank_k_labels):\n",
    "    #num_of_correct = rank_k_labels.count(trueLabel)\n",
    "    correct_list = [trueLabel == this_label for this_label in rank_k_labels]\n",
    "    rank_k_labels\n",
    "    \n",
    "    \n",
    "    precision = [] #list of size k\n",
    "    recall = [] #list of size k\n",
    "    max_list = []\n",
    "    for i, label in enumerate(rank_k_labels):\n",
    "        precision.append(sum(correct_list[:i])/len(correct_list[:i]))\n",
    "        recall.append()\n",
    "\n",
    "def get_accuracy(k, N):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(gallery_images) \n",
    "    for index, query_index in enumerate((train_idxs['query_idx'].flatten()-1).tolist()):\n",
    "        print(index)\n",
    "        print(query_index)\n",
    "        if (index % 10 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "        #print(query_labels[index], query_index, N_indices)\n",
    "        topN_gallery_images = gallery_images[N_indices[0]]\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "        #topN_gallery_indices = [np.where(np.all(features_np == image, axis=1))[0][0] for image in topN_gallery_images]\n",
    "        #print(time.time()-forLoopStart)\n",
    "        #print('topN indices', topN_gallery_indices.flatten().tolist())\n",
    "        #print('n_indices', N_indices[0])\n",
    "        #print(train_idxs['gallery_idx'][N_indices[0]])\n",
    "        reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "        AP = calcAP(query_labels[index][0], reduced_topN_labels[:k])\n",
    "        if index == 300:\n",
    "            break\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2048)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_np[[2, 3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "21\n",
      "Index:  0  & time taken:  2.1404974460601807\n",
      "1\n",
      "26\n",
      "2\n",
      "48\n",
      "3\n",
      "54\n",
      "4\n",
      "58\n",
      "5\n",
      "62\n",
      "6\n",
      "99\n",
      "7\n",
      "101\n",
      "8\n",
      "127\n",
      "9\n",
      "134\n",
      "10\n",
      "153\n",
      "Index:  10  & time taken:  3.4844398498535156\n",
      "11\n",
      "156\n",
      "12\n",
      "200\n",
      "13\n",
      "204\n",
      "14\n",
      "255\n",
      "15\n",
      "263\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-521-1c428b865f7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-519-ef9d28ed83e9>\u001b[0m in \u001b[0;36mget_accuracy\u001b[1;34m(k, N)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" & time taken: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mN_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneigh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2048\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[1;31m#print(query_labels[index], query_index, N_indices)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mtopN_gallery_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgallery_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mN_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[0;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 385\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m             )\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_accuracy(10, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "total_number_of_labels = np.unique(train_idxs['labels'])[-1]\n",
    "n_clusters = 3 #total_number_of_labels\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmeans.fit(gallery_images)\n",
    "#print(kmeans.labels_)\n",
    "index_and_cluster = [(index, label) for index, label in zip(train_idxs['gallery_idx'].flatten(), kmeans.labels_)]\n",
    "#np.unique(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_indices_in_cluster(c): \n",
    "    cluster_labels = [pair[0] for pair in index_and_cluster if pair[1] == c]\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_cluster(k, N, c_g_indices, query_index, index):\n",
    "    list_of_truths = []\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(features_np[c_g_indices])   #new_gallery_labels)\n",
    "    \n",
    "    \n",
    "    N_distances, N_indices = neigh.kneighbors(features_np[query_index].reshape(1, -1), N)\n",
    "    #print(query_labels[index], query_index, N_indices)\n",
    "    #topN_c_g_images = features_np[c_g_indices][N_indices[0]]\n",
    "    topN_c_g_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "    \n",
    "    reduced_topN_indices, reduced_topN_labels = remove_indices(topN_c_g_indices, query_index)\n",
    "    \n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "def knn_clustering(k, N):\n",
    "    class_success = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if (index % 10 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        cluster = kmeans.predict(query_images[index].reshape(1,-1))\n",
    "        cluster_gallery_indices = img_indices_in_cluster(cluster)\n",
    "        class_success.append(img_cluster(k, N, cluster_gallery_indices, query_index, index))\n",
    "        \n",
    "        \n",
    "        if index == 100:\n",
    "            break\n",
    "     #over-all accuracy\n",
    "    acc = sum(class_success)/len(class_success)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  0.00043892860412597656\n",
      "Index:  10  & time taken:  2.5827829837799072\n",
      "Index:  20  & time taken:  5.329355955123901\n",
      "Index:  30  & time taken:  7.973233938217163\n",
      "Index:  40  & time taken:  10.791098833084106\n",
      "Index:  50  & time taken:  13.536258935928345\n",
      "Index:  60  & time taken:  16.281173944473267\n",
      "Index:  70  & time taken:  18.76628875732422\n",
      "Index:  80  & time taken:  21.52734112739563\n",
      "Index:  90  & time taken:  24.169163942337036\n",
      "Index:  100  & time taken:  26.962733030319214\n",
      "0.039603960396039604\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "N = 100\n",
    "knn_clustering(k, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobi Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting distances from the average gallery vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of unique labels in gallery \n",
    "len(np.unique(gallery_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.cov(np.transpose(gallery_images))\n",
    "A = np.linalg.inv(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 2048)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'S' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-499-df23348f6d3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'S' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5328, 2048)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_gallery_images = gallery_images.mean(axis=0)     # to take the mean of each column (colummn -> feature)\n",
    "mean_gallery_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_set_distances = [np.sqrt(np.dot(np.dot(np.transpose(query_image-mean_gallery_images),A), query_image-mean_gallery_images))\n",
    "                      for query_image in query_images]\n",
    "np.array(query_set_distances).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting distances using kNN and Mahalanobi Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='mahalanobis',\n",
       "         metric_params={'V': array([[ 0.09833, -0.00735, ..., -0.00826, -0.00833],\n",
       "       [-0.00735,  0.20639, ..., -0.00024, -0.00667],\n",
       "       ...,\n",
       "       [-0.00826, -0.00024, ...,  0.22353,  0.06679],\n",
       "       [-0.00833, -0.00667, ...,  0.06679,  0.10489]])},\n",
       "         n_jobs=1, n_neighbors=100, p=2, radius=1.0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_md = NearestNeighbors(n_neighbors=N,metric='mahalanobis', \n",
    "            metric_params= {'V': np.cov(np.transpose(gallery_images))})\n",
    "neigh_md.fit(gallery_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_mahalanobi(k, N):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()[:300]):\n",
    "        if (index % 50 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh_md.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "        topN_gallery_images = gallery_images[N_indices[0]]\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "        reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(\"Avg Accuracy is: \", acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  8.082389831542969e-05\n",
      "Index:  50  & time taken:  1194.6821658611298\n",
      "Index:  100  & time taken:  2801.5326719284058\n",
      "Index:  150  & time taken:  4013.9011237621307\n",
      "Index:  200  & time taken:  5203.121114730835\n",
      "Index:  250  & time taken:  6391.557485818863\n",
      "Avg Accuracy is:  0.13666666666666666\n",
      "Index:  0  & time taken:  7.224082946777344e-05\n",
      "Index:  50  & time taken:  1187.0171492099762\n",
      "Index:  100  & time taken:  2373.66286110878\n",
      "Index:  150  & time taken:  3560.3639900684357\n",
      "Index:  200  & time taken:  4746.637277126312\n",
      "Index:  250  & time taken:  5932.8617470264435\n",
      "Avg Accuracy is:  0.2833333333333333\n",
      "Index:  0  & time taken:  9.083747863769531e-05\n",
      "Index:  50  & time taken:  1186.3573276996613\n",
      "Index:  100  & time taken:  2372.715752840042\n",
      "Index:  150  & time taken:  3559.498749732971\n",
      "Index:  200  & time taken:  4745.957722663879\n",
      "Index:  250  & time taken:  5932.393654823303\n",
      "Avg Accuracy is:  0.4533333333333333\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "k = [1, 10, 100]\n",
    "acc_k2 = []\n",
    "for k_val in k: \n",
    "    acc = get_accuracy_mahalanobi(k_val, N)\n",
    "    acc_k2.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09090909090909091, 0.18181818181818182, 0.36363636363636365]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13666666666666666, 0.2833333333333333, 0.4533333333333333]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=100, p=2, radius=1.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "neigh_c = NearestNeighbors(n_neighbors=N,metric='cosine')\n",
    "neigh_c.fit(gallery_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  7.700920104980469e-05\n",
      "Index:  50  & time taken:  4.227119207382202\n",
      "Index:  100  & time taken:  8.423174142837524\n",
      "Index:  150  & time taken:  12.630351066589355\n",
      "Index:  200  & time taken:  16.83267116546631\n",
      "Index:  250  & time taken:  21.04805612564087\n",
      "Avg Accuracy is:  0.49\n",
      "Index:  0  & time taken:  5.1975250244140625e-05\n",
      "Index:  50  & time taken:  4.1925787925720215\n",
      "Index:  100  & time taken:  8.413705825805664\n",
      "Index:  150  & time taken:  12.6040678024292\n",
      "Index:  200  & time taken:  16.792085886001587\n",
      "Index:  250  & time taken:  20.98653793334961\n",
      "Avg Accuracy is:  0.74\n",
      "Index:  0  & time taken:  5.3882598876953125e-05\n",
      "Index:  50  & time taken:  4.198216199874878\n",
      "Index:  100  & time taken:  8.467583894729614\n",
      "Index:  150  & time taken:  12.67863917350769\n",
      "Index:  200  & time taken:  16.884459972381592\n",
      "Index:  250  & time taken:  21.093831062316895\n",
      "Avg Accuracy is:  0.91\n"
     ]
    }
   ],
   "source": [
    "def get_acc_gen(k, N, index, query_index):\n",
    "    N_distances, N_indices = neigh_c.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "    topN_gallery_images = gallery_images[N_indices[0]]\n",
    "    forLoopStart = time.time()\n",
    "    topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "    reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "k = [1, 10, 100]\n",
    "acc_k3 = []\n",
    "for k_val in k:\n",
    "    list_of_truths = [] \n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()[:300]):\n",
    "        if (index % 50 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        truth_false = get_acc_gen(k_val, N, index, query_index)\n",
    "        list_of_truths.append(truth_false)\n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(\"Avg Accuracy is: \", acc)\n",
    "    acc_k3.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
