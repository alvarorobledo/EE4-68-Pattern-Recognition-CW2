{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern recognition CW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with 6 main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "camId : which camera was used to get the shot (1 or 2)\n",
    "filelist: names of the images (with format x_label_camId_index.png)\n",
    "labels: class of the image (which person's image is it?)\n",
    "query_idx: indexes of test set\n",
    "gallery_idx: indexes of test set used for kNN \n",
    "train_idx: indexes of training and validation set\n",
    "\"\"\"   \n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with the feature vectors of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 2048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "features_np = np.array(features) #list of features converted to an array \n",
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5328, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1],\n",
       "       [    2],\n",
       "       [    3],\n",
       "       ...,\n",
       "       [14094],\n",
       "       [14095],\n",
       "       [14096]], dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['train_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7368+5328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['query_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12696+1400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classification for query set on gallery set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_filename(image_index): \n",
    "    name = str(train_idxs['filelist'][image_index][0][0])\n",
    "    [dc, label, camId, index] = name.split('_')\n",
    "    return label, camId\n",
    "\n",
    "def delete_images(query_image, query_index, gallery_images, gallery_labels):\n",
    "    gallery_names = train_idxs['filelist'][train_idxs['gallery_idx'].flatten()]\n",
    "    query_label, query_camId = extract_info_from_filename(query_index)\n",
    "    new_gallery_images = []\n",
    "    new_gallery_labels = []\n",
    "    for img, name in zip(gallery_images, gallery_names):\n",
    "        [dc, label_g, camId_g, index] = str(name[0][0]).split('_')\n",
    "        if [int(label_g), int(camId_g)] != [int(query_label), int(query_camId)]:\n",
    "            new_gallery_images.append(img)\n",
    "            new_gallery_labels.append(int(label_g))\n",
    "    return new_gallery_images, new_gallery_labels\n",
    "\n",
    "def score_rank(query_label, rank_k, new_gallery_labels):\n",
    "    #print(rank_k)\n",
    "    rank_k_labels = np.array(new_gallery_labels)[rank_k] #extract the labels which are of rank k\n",
    "    return (query_label[0] in rank_k_labels) #return true if query label in rank k, else false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNClassification_deletions(query_image, query_index, gallery_images, gallery_labels, k):\n",
    "    neigh = NearestNeighbors(n_neighbors=k, n_jobs=-1)\n",
    "    new_gallery_images, new_gallery_labels = delete_images(query_image, query_index, gallery_images, gallery_labels)\n",
    "    neigh.fit(new_gallery_images)   #new_gallery_labels)\n",
    "    distances, indices = neigh.kneighbors(query_image, k)\n",
    "    return distances, indices, new_gallery_labels #neigh.score(query_image, query_label), neigh.predict(query_image), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gallery_labels = train_idxs['labels'][train_idxs['gallery_idx'].flatten()]\n",
    "query_labels = train_idxs['labels'][train_idxs['query_idx'].flatten()]\n",
    "\n",
    "query_images = features_np[train_idxs['query_idx'].flatten()]\n",
    "gallery_images = features_np[train_idxs['gallery_idx'].flatten()]\n",
    "\n",
    "def get_accuracy_for_k_ranks(k):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if(index < 101):\n",
    "            if (index % 10 == 0):\n",
    "                print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "\n",
    "            #perform NN Classification and extract top k ranks \n",
    "            dist, rank_k_indices, new_gallery_labels = NNClassification_deletions(query_images[index].reshape(1, 2048), query_index, gallery_images, gallery_labels, k)\n",
    "            #calculate the score (true/false) for top k images and query image recognition\n",
    "            score = score_rank(query_labels[index], rank_k_indices, new_gallery_labels)\n",
    "            #create a list of scores to get overall accuracy later on\n",
    "            list_of_truths.append(score)\n",
    "    \n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['1_022_2_06.png'], dtype='<U14')], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['filelist'][204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98361254, 0.33195475, 0.26549727, ..., 0.02350602, 0.08491972,\n",
       "        0.00514889],\n",
       "       [1.30696166, 0.22219124, 0.62375975, ..., 0.02954952, 0.37348923,\n",
       "        0.05303315],\n",
       "       [0.29322624, 0.55588913, 0.06961903, ..., 0.15892459, 0.21527511,\n",
       "        0.09551907],\n",
       "       ...,\n",
       "       [0.7593497 , 0.24537075, 2.19513273, ..., 0.47061139, 1.35971546,\n",
       "        0.46198806],\n",
       "       [0.48667279, 0.49618778, 0.30824399, ..., 0.04450084, 1.28799629,\n",
       "        0.37683338],\n",
       "       [0.05719076, 0.60635394, 0.58300596, ..., 0.40994745, 1.37061644,\n",
       "        0.55975795]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_labels = train_idxs['labels'][train_idxs['gallery_idx'].flatten()]\n",
    "query_labels = train_idxs['labels'][train_idxs['query_idx'].flatten()]\n",
    "\n",
    "query_images = features_np[train_idxs['query_idx'].flatten()]\n",
    "gallery_images = features_np[train_idxs['gallery_idx'].flatten()]\n",
    "\n",
    "N=100\n",
    "\n",
    "\n",
    "def remove_indices(n_indices, query_index):\n",
    "    query_label, query_camId = extract_info_from_filename(query_index)\n",
    "    n_names = train_idxs['filelist'][n_indices]\n",
    "    #k_images = features_np[k_indices]\n",
    "    #print(k_names.shape, k_names[0], k_images[0])\n",
    "    final_n_indices = []\n",
    "    final_n_labels = []\n",
    "    for index, name in zip(n_indices, n_names):\n",
    "        [dc, label_g, camId_g, index_g] = str(name[0][0]).split('_')\n",
    "        #print(str(name[0][0]).split('_'))\n",
    "        #print(index)\n",
    "        if [int(label_g), int(camId_g)] != [int(query_label), int(query_camId)]:\n",
    "            final_n_indices.append(index)\n",
    "            final_n_labels.append(int(label_g))\n",
    "    return final_n_indices, final_n_labels\n",
    "\n",
    "def get_accuracy(k, N):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1)\n",
    "    neigh.fit(gallery_images)   #new_gallery_labels)\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if (index % 10 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "        #print(query_labels[index], query_index, N_indices)\n",
    "        topN_gallery_images = gallery_images[N_indices[0]]\n",
    "        \n",
    "        topN_gallery_indices = [np.where(np.all(features_np == image, axis=1))[0][0] for image in topN_gallery_images]\n",
    "        #print('topN indices', topN_gallery_indices)\n",
    "        #print('n_indices', N_indices[0])\n",
    "        reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "        if index == 100:\n",
    "            break\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths) \n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  0.6375007629394531\n",
      "Index:  10  & time taken:  36.28590679168701\n",
      "Index:  20  & time taken:  69.53656077384949\n",
      "Index:  30  & time taken:  104.77642774581909\n",
      "Index:  40  & time taken:  136.43121576309204\n",
      "Index:  50  & time taken:  170.34395289421082\n",
      "Index:  60  & time taken:  202.93267583847046\n",
      "Index:  70  & time taken:  234.7717638015747\n",
      "Index:  80  & time taken:  266.59189677238464\n",
      "Index:  90  & time taken:  299.0750877857208\n",
      "Index:  100  & time taken:  331.22363471984863\n",
      "0.8910891089108911\n",
      " "
     ]
    }
   ],
   "source": [
    "%prun get_accuracy(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy_for_k_ranks(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  0.0\n",
      "Index:  10  & time taken:  23.64891242980957\n",
      "Index:  20  & time taken:  47.139809370040894\n",
      "Index:  30  & time taken:  71.5410213470459\n",
      "Index:  40  & time taken:  95.63419580459595\n",
      "Index:  50  & time taken:  119.49739098548889\n",
      "Index:  60  & time taken:  142.7541127204895\n",
      "Index:  70  & time taken:  165.4745020866394\n",
      "Index:  80  & time taken:  188.19400596618652\n",
      "Index:  90  & time taken:  211.17892265319824\n",
      "Index:  100  & time taken:  233.9523696899414\n",
      " "
     ]
    }
   ],
   "source": [
    "%prun get_accuracy_for_k_ranks(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
