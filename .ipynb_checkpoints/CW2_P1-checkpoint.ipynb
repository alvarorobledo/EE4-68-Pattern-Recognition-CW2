{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern recognition CW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with 6 main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "camId : which camera was used to get the shot (1 or 2)\n",
    "filelist: names of the images (with format x_label_camId_index.png)\n",
    "labels: class of the image (which person's image is it?)\n",
    "query_idx: indexes of test set\n",
    "gallery_idx: indexes of test set used for kNN \n",
    "train_idx: indexes of training and validation set\n",
    "\"\"\"   \n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with the feature vectors of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "features_np = np.array(features) #list of features converted to an array \n",
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1467"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_idxs['labels'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   21],\n",
       "       [   23],\n",
       "       [   24],\n",
       "       ...,\n",
       "       [14062],\n",
       "       [14064],\n",
       "       [14065]], dtype=uint16)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1],\n",
       "       [    2],\n",
       "       [    3],\n",
       "       ...,\n",
       "       [14094],\n",
       "       [14095],\n",
       "       [14096]], dtype=uint16)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['train_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12696"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7368+5328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['query_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14096"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12696+1400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classification for query set on gallery set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_filename(image_index): \n",
    "    name = str(train_idxs['filelist'][image_index][0][0])\n",
    "    [dc, label, camId, index] = name.split('_')\n",
    "    return label, camId\n",
    "\n",
    "def delete_images(query_image, query_index, gallery_images, gallery_labels):\n",
    "    gallery_names = train_idxs['filelist'][train_idxs['gallery_idx'].flatten()]\n",
    "    query_label, query_camId = extract_info_from_filename(query_index)\n",
    "    new_gallery_images = []\n",
    "    new_gallery_labels = []\n",
    "    for img, name in zip(gallery_images, gallery_names):\n",
    "        [dc, label_g, camId_g, index] = str(name[0][0]).split('_')\n",
    "        if [int(label_g), int(camId_g)] != [int(query_label), int(query_camId)]:\n",
    "            new_gallery_images.append(img)\n",
    "            new_gallery_labels.append(int(label_g))\n",
    "    return new_gallery_images, new_gallery_labels\n",
    "\n",
    "def score_rank(query_label, rank_k, new_gallery_labels):\n",
    "    #print(rank_k)\n",
    "    rank_k_labels = np.array(new_gallery_labels)[rank_k #extract the labels which are of rank k\n",
    "    return (query_label[0] in rank_k_labels) #return true if query label in rank k, else false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNClassification_deletions(query_image, query_index, gallery_images, gallery_labels, k):\n",
    "    neigh = NearestNeighbors(n_neighbors=k, n_jobs=-1)\n",
    "    new_gallery_images, new_gallery_labels = delete_images(query_image, query_index, gallery_images, gallery_labels)\n",
    "    neigh.fit(new_gallery_images)   #new_gallery_labels)\n",
    "    distances, indices = neigh.kneighbors(query_image, k)\n",
    "    return distances, indices, new_gallery_labels #neigh.score(query_image, query_label), neigh.predict(query_image), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gallery_labels = train_idxs['labels'][train_idxs['gallery_idx'].flatten()]\n",
    "query_labels = train_idxs['labels'][train_idxs['query_idx'].flatten()]\n",
    "\n",
    "query_images = features_np[train_idxs['query_idx'].flatten()]\n",
    "gallery_images = features_np[train_idxs['gallery_idx'].flatten()]\n",
    "\n",
    "def get_accuracy_for_k_ranks(k):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if(index < 101):\n",
    "            if (index % 10 == 0):\n",
    "                print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "\n",
    "            #perform NN Classification and extract top k ranks \n",
    "            dist, rank_k_indices, new_gallery_labels = NNClassification_deletions(query_images[index].reshape(1, 2048), query_index, gallery_images, gallery_labels, k)\n",
    "            #calculate the score (true/false) for top k images and query image recognition\n",
    "            score = score_rank(query_labels[index], rank_k_indices, new_gallery_labels)\n",
    "            #create a list of scores to get overall accuracy later on\n",
    "            list_of_truths.append(score)\n",
    "    \n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['1_022_2_06.png'], dtype='<U14')], dtype=object)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['filelist'][204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98361254, 0.33195475, 0.26549727, ..., 0.02350602, 0.08491972,\n",
       "        0.00514889],\n",
       "       [1.30696166, 0.22219124, 0.62375975, ..., 0.02954952, 0.37348923,\n",
       "        0.05303315],\n",
       "       [0.29322624, 0.55588913, 0.06961903, ..., 0.15892459, 0.21527511,\n",
       "        0.09551907],\n",
       "       ...,\n",
       "       [0.7593497 , 0.24537075, 2.19513273, ..., 0.47061139, 1.35971546,\n",
       "        0.46198806],\n",
       "       [0.48667279, 0.49618778, 0.30824399, ..., 0.04450084, 1.28799629,\n",
       "        0.37683338],\n",
       "       [0.05719076, 0.60635394, 0.58300596, ..., 0.40994745, 1.37061644,\n",
       "        0.55975795]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_labels = train_idxs['labels'][train_idxs['gallery_idx'].flatten()]\n",
    "query_labels = train_idxs['labels'][train_idxs['query_idx'].flatten()]\n",
    "\n",
    "query_images = features_np[train_idxs['query_idx'].flatten()]\n",
    "gallery_images = features_np[train_idxs['gallery_idx'].flatten()]\n",
    "\n",
    "N=100\n",
    "\n",
    "\n",
    "def remove_indices(n_indices, query_index):\n",
    "    query_label, query_camId = extract_info_from_filename(query_index)\n",
    "    n_names = train_idxs['filelist'][n_indices]\n",
    "    #k_images = features_np[k_indices]\n",
    "    #print(k_names.shape, k_names[0], k_images[0])\n",
    "    final_n_indices = []\n",
    "    final_n_labels = []\n",
    "    for index, name in zip(n_indices, n_names):\n",
    "        [dc, label_g, camId_g, index_g] = str(name[0][0]).split('_')\n",
    "        #print(str(name[0][0]).split('_'))\n",
    "        #print(index)\n",
    "        if [int(label_g), int(camId_g)] != [int(query_label), int(query_camId)]:\n",
    "            final_n_indices.append(index)\n",
    "            final_n_labels.append(int(label_g))\n",
    "    return final_n_indices, final_n_labels\n",
    "\n",
    "def get_accuracy(k, N, gallery_images):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(gallery_images)   #new_gallery_labels)\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if (index % 10 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "        #print(query_labels[index], query_index, N_indices)\n",
    "        topN_gallery_images = gallery_images[N_indices[0]]\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "        #topN_gallery_indices = [np.where(np.all(features_np == image, axis=1))[0][0] for image in topN_gallery_images]\n",
    "        #print(time.time()-forLoopStart)\n",
    "        #print('topN indices', topN_gallery_indices.flatten().tolist())\n",
    "        #print('n_indices', N_indices[0])\n",
    "        #print(train_idxs['gallery_idx'][N_indices[0]])\n",
    "        reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "        if index == 300:\n",
    "            break\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2048)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_np[[2, 3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  1.1097545623779297\n",
      "Index:  10  & time taken:  2.233020067214966\n",
      "Index:  20  & time taken:  3.304171323776245\n",
      "Index:  30  & time taken:  4.40855860710144\n",
      "Index:  40  & time taken:  5.501349449157715\n",
      "Index:  50  & time taken:  6.595091819763184\n",
      "Index:  60  & time taken:  7.727085828781128\n",
      "Index:  70  & time taken:  8.817773818969727\n",
      "Index:  80  & time taken:  9.915739059448242\n",
      "Index:  90  & time taken:  11.015377283096313\n",
      "Index:  100  & time taken:  12.136348009109497\n",
      "Index:  110  & time taken:  13.257834434509277\n",
      "Index:  120  & time taken:  14.34682846069336\n",
      "Index:  130  & time taken:  15.468301057815552\n",
      "Index:  140  & time taken:  16.57993507385254\n",
      "Index:  150  & time taken:  17.694861888885498\n",
      "Index:  160  & time taken:  18.808980703353882\n",
      "Index:  170  & time taken:  19.907105445861816\n",
      "Index:  180  & time taken:  20.996891498565674\n",
      "Index:  190  & time taken:  22.087839126586914\n",
      "Index:  200  & time taken:  23.182602882385254\n",
      "Index:  210  & time taken:  24.287029504776\n",
      "Index:  220  & time taken:  25.3805570602417\n",
      "Index:  230  & time taken:  26.49273681640625\n",
      "Index:  240  & time taken:  27.575350046157837\n",
      "Index:  250  & time taken:  28.68804144859314\n",
      "Index:  260  & time taken:  29.78746199607849\n",
      "Index:  270  & time taken:  30.902979612350464\n",
      "Index:  280  & time taken:  31.996840000152588\n",
      "Index:  290  & time taken:  33.05958867073059\n",
      "Index:  300  & time taken:  34.16751980781555\n",
      "0.4684385382059801\n",
      " "
     ]
    }
   ],
   "source": [
    "%prun get_accuracy(1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "total_number_of_labels = np.unique(train_idxs['labels'])[-1]\n",
    "n_clusters = total_number_of_labels #total_number_of_labels\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmeans.fit(gallery_images)\n",
    "#print(kmeans.labels_)\n",
    "index_and_cluster = [(index, label) for index, label in zip(train_idxs['gallery_idx'].flatten(), kmeans.labels_)]\n",
    "#np.unique(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_indices_in_cluster(c): \n",
    "    cluster_labels = [pair[0] for pair in index_and_cluster if pair[1] == c]\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_cluster(k, N, c_g_indices, query_index, index):\n",
    "    list_of_truths = []\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(features_np[c_g_indices])   #new_gallery_labels)\n",
    "    \n",
    "    \n",
    "    N_distances, N_indices = neigh.kneighbors(features_np[query_index].reshape(1, -1), N)\n",
    "    #print(query_labels[index], query_index, N_indices)\n",
    "    #topN_c_g_images = features_np[c_g_indices][N_indices[0]]\n",
    "    topN_c_g_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "    \n",
    "    reduced_topN_indices, reduced_topN_labels = remove_indices(topN_c_g_indices, query_index)\n",
    "    \n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "def knn_clustering(k, N):\n",
    "    class_success = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if (index % 10 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        cluster = kmeans.predict(query_images[index].reshape(1,-1))\n",
    "        cluster_gallery_indices = img_indices_in_cluster(cluster)\n",
    "        class_success.append(img_cluster(k, N, cluster_gallery_indices, query_index, index))\n",
    "        \n",
    "        \n",
    "        if index == 100:\n",
    "            break\n",
    "     #over-all accuracy\n",
    "    acc = sum(class_success)/len(class_success)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "N = 100\n",
    "knn_clustering(k, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1.30696166 0.22219124 0.62375975 ... 0.02954952 0.37348923 0.05303315].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-412-bc5640c787e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cluster_centers_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_labels_inertia\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[0mexpected_n_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1.30696166 0.22219124 0.62375975 ... 0.02954952 0.37348923 0.05303315].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#kmeans.predict(query_images[1])\n",
    "for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "    cluster = kmeans.predict(query_images[index].reshape(1,-1))\n",
    "    \n",
    "    cluster_gallery_indices = img_indices_in_cluster(cluster)\n",
    "    \n",
    "    \n",
    "    #actual_label = query_labels[index]\n",
    "    #if predicted_label == actual_label:\n",
    "        \n",
    "\n",
    "\n",
    "#KMeansClustering(total_number_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([797])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(query_images[1].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=uint16)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
