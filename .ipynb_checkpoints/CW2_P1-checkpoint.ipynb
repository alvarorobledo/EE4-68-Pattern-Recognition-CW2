{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern recognition CW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with 6 main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "camId : which camera was used to get the shot (1 or 2)\n",
    "filelist: names of the images (with format x_label_camId_index.png)\n",
    "labels: class of the image (which person's image is it?)\n",
    "query_idx: indexes of test set\n",
    "gallery_idx: indexes of test set used for kNN \n",
    "train_idx: indexes of training and validation set\n",
    "\"\"\"   \n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with the feature vectors of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 2048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "features_np = np.array(features) #list of features converted to an array \n",
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1467"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_idxs['labels'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5328, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1],\n",
       "       [    2],\n",
       "       [    3],\n",
       "       ...,\n",
       "       [14094],\n",
       "       [14095],\n",
       "       [14096]], dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['train_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7368+5328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['query_idx'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "12696+1400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classification for query set on gallery set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_filename(image_index): \n",
    "    name = str(train_idxs['filelist'][image_index][0][0])\n",
    "    [dc, label, camId, index] = name.split('_')\n",
    "    return label, camId\n",
    "\n",
    "def delete_images(query_image, query_index, gallery_images, gallery_labels):\n",
    "    gallery_names = train_idxs['filelist'][train_idxs['gallery_idx'].flatten()]\n",
    "    query_label, query_camId = extract_info_from_filename(query_index)\n",
    "    new_gallery_images = []\n",
    "    new_gallery_labels = []\n",
    "    for img, name in zip(gallery_images, gallery_names):\n",
    "        [dc, label_g, camId_g, index] = str(name[0][0]).split('_')\n",
    "        if [int(label_g), int(camId_g)] != [int(query_label), int(query_camId)]:\n",
    "            new_gallery_images.append(img)\n",
    "            new_gallery_labels.append(int(label_g))\n",
    "    return new_gallery_images, new_gallery_labels\n",
    "\n",
    "def score_rank(query_label, rank_k, new_gallery_labels):\n",
    "    #print(rank_k)\n",
    "    rank_k_labels = np.array(new_gallery_labels)[rank_k] #extract the labels which are of rank k\n",
    "    return (query_label[0] in rank_k_labels) #return true if query label in rank k, else false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNClassification_deletions(query_image, query_index, gallery_images, gallery_labels, k):\n",
    "    neigh = NearestNeighbors(n_neighbors=k, n_jobs=-1)\n",
    "    new_gallery_images, new_gallery_labels = delete_images(query_image, query_index, gallery_images, gallery_labels)\n",
    "    neigh.fit(new_gallery_images)   #new_gallery_labels)\n",
    "    distances, indices = neigh.kneighbors(query_image, k)\n",
    "    return distances, indices, new_gallery_labels #neigh.score(query_image, query_label), neigh.predict(query_image), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gallery_labels = train_idxs['labels'][train_idxs['gallery_idx'].flatten()]\n",
    "query_labels = train_idxs['labels'][train_idxs['query_idx'].flatten()]\n",
    "\n",
    "query_images = features_np[train_idxs['query_idx'].flatten()]\n",
    "gallery_images = features_np[train_idxs['gallery_idx'].flatten()]\n",
    "\n",
    "def get_accuracy_for_k_ranks(k):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if(index < 101):\n",
    "            if (index % 10 == 0):\n",
    "                print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "\n",
    "            #perform NN Classification and extract top k ranks \n",
    "            dist, rank_k_indices, new_gallery_labels = NNClassification_deletions(query_images[index].reshape(1, 2048), query_index, gallery_images, gallery_labels, k)\n",
    "            #calculate the score (true/false) for top k images and query image recognition\n",
    "            score = score_rank(query_labels[index], rank_k_indices, new_gallery_labels)\n",
    "            #create a list of scores to get overall accuracy later on\n",
    "            list_of_truths.append(score)\n",
    "    \n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   21,    23,    24, ..., 14062, 14064, 14065], dtype=uint16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['gallery_idx'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array(['1_022_2_06.png'], dtype='<U14')], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs['filelist'][204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98361254, 0.33195475, 0.26549727, ..., 0.02350602, 0.08491972,\n",
       "        0.00514889],\n",
       "       [1.30696166, 0.22219124, 0.62375975, ..., 0.02954952, 0.37348923,\n",
       "        0.05303315],\n",
       "       [0.29322624, 0.55588913, 0.06961903, ..., 0.15892459, 0.21527511,\n",
       "        0.09551907],\n",
       "       ...,\n",
       "       [0.7593497 , 0.24537075, 2.19513273, ..., 0.47061139, 1.35971546,\n",
       "        0.46198806],\n",
       "       [0.48667279, 0.49618778, 0.30824399, ..., 0.04450084, 1.28799629,\n",
       "        0.37683338],\n",
       "       [0.05719076, 0.60635394, 0.58300596, ..., 0.40994745, 1.37061644,\n",
       "        0.55975795]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_labels = train_idxs['labels'][train_idxs['gallery_idx'].flatten()]\n",
    "query_labels = train_idxs['labels'][train_idxs['query_idx'].flatten()]\n",
    "\n",
    "query_images = features_np[train_idxs['query_idx'].flatten()]\n",
    "gallery_images = features_np[train_idxs['gallery_idx'].flatten()]\n",
    "\n",
    "N=100\n",
    "\n",
    "\n",
    "def remove_indices(n_indices, query_index):\n",
    "    query_label, query_camId = extract_info_from_filename(query_index)\n",
    "    n_names = train_idxs['filelist'][n_indices]\n",
    "    #k_images = features_np[k_indices]\n",
    "    #print(k_names.shape, k_names[0], k_images[0])\n",
    "    final_n_indices = []\n",
    "    final_n_labels = []\n",
    "    for index, name in zip(n_indices, n_names):\n",
    "        [dc, label_g, camId_g, index_g] = str(name[0][0]).split('_')\n",
    "        #print(str(name[0][0]).split('_'))\n",
    "        #print(index)\n",
    "        if [int(label_g), int(camId_g)] != [int(query_label), int(query_camId)]:\n",
    "            final_n_indices.append(index)\n",
    "            final_n_labels.append(int(label_g))\n",
    "    return final_n_indices, final_n_labels\n",
    "\n",
    "def get_accuracy(k, N):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(gallery_images)   #new_gallery_labels)\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if (index % 10 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "        #print(query_labels[index], query_index, N_indices)\n",
    "        topN_gallery_images = gallery_images[N_indices[0]]\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "        #topN_gallery_indices = [np.where(np.all(features_np == image, axis=1))[0][0] for image in topN_gallery_images]\n",
    "        #print(time.time()-forLoopStart)\n",
    "        #print('topN indices', topN_gallery_indices.flatten().tolist())\n",
    "        #print('n_indices', N_indices[0])\n",
    "        #print(train_idxs['gallery_idx'][N_indices[0]])\n",
    "        reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "        if index == 300:\n",
    "            break\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2048)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_np[[2, 3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  0.6633329391479492\n",
      "Index:  10  & time taken:  1.7301599979400635\n",
      "Index:  20  & time taken:  2.7969608306884766\n",
      "Index:  30  & time taken:  3.8662068843841553\n",
      "Index:  40  & time taken:  4.922598123550415\n",
      "Index:  50  & time taken:  5.985350131988525\n",
      "Index:  60  & time taken:  7.051974058151245\n",
      "Index:  70  & time taken:  8.112435102462769\n",
      "Index:  80  & time taken:  9.16952109336853\n",
      "Index:  90  & time taken:  10.236074924468994\n",
      "Index:  100  & time taken:  11.31096601486206\n",
      "Index:  110  & time taken:  12.360049962997437\n",
      "Index:  120  & time taken:  13.427722930908203\n",
      "Index:  130  & time taken:  14.492151021957397\n",
      "Index:  140  & time taken:  15.546682119369507\n",
      "Index:  150  & time taken:  16.605628967285156\n",
      "Index:  160  & time taken:  17.666258096694946\n",
      "Index:  170  & time taken:  18.732553958892822\n",
      "Index:  180  & time taken:  19.792661905288696\n",
      "Index:  190  & time taken:  20.844604969024658\n",
      "Index:  200  & time taken:  21.90824007987976\n",
      "Index:  210  & time taken:  22.965630769729614\n",
      "Index:  220  & time taken:  24.02580189704895\n",
      "Index:  230  & time taken:  25.08322811126709\n",
      "Index:  240  & time taken:  26.13739585876465\n",
      "Index:  250  & time taken:  27.202621936798096\n",
      "Index:  260  & time taken:  28.284141063690186\n",
      "Index:  270  & time taken:  29.348734855651855\n",
      "Index:  280  & time taken:  30.424793004989624\n",
      "Index:  290  & time taken:  31.48853087425232\n",
      "Index:  300  & time taken:  32.545544147491455\n",
      "0.4684385382059801\n",
      " "
     ]
    }
   ],
   "source": [
    "%prun get_accuracy(1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "total_number_of_labels = np.unique(train_idxs['labels'])[-1]\n",
    "n_clusters = 3 #total_number_of_labels\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmeans.fit(gallery_images)\n",
    "#print(kmeans.labels_)\n",
    "index_and_cluster = [(index, label) for index, label in zip(train_idxs['gallery_idx'].flatten(), kmeans.labels_)]\n",
    "#np.unique(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_indices_in_cluster(c): \n",
    "    cluster_labels = [pair[0] for pair in index_and_cluster if pair[1] == c]\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_cluster(k, N, c_g_indices, query_index, index):\n",
    "    list_of_truths = []\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(features_np[c_g_indices])   #new_gallery_labels)\n",
    "    \n",
    "    \n",
    "    N_distances, N_indices = neigh.kneighbors(features_np[query_index].reshape(1, -1), N)\n",
    "    #print(query_labels[index], query_index, N_indices)\n",
    "    #topN_c_g_images = features_np[c_g_indices][N_indices[0]]\n",
    "    topN_c_g_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "    \n",
    "    reduced_topN_indices, reduced_topN_labels = remove_indices(topN_c_g_indices, query_index)\n",
    "    \n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "def knn_clustering(k, N):\n",
    "    class_success = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()):\n",
    "        if (index % 10 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        cluster = kmeans.predict(query_images[index].reshape(1,-1))\n",
    "        cluster_gallery_indices = img_indices_in_cluster(cluster)\n",
    "        class_success.append(img_cluster(k, N, cluster_gallery_indices, query_index, index))\n",
    "        \n",
    "        \n",
    "        if index == 100:\n",
    "            break\n",
    "     #over-all accuracy\n",
    "    acc = sum(class_success)/len(class_success)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  0.00043892860412597656\n",
      "Index:  10  & time taken:  2.5827829837799072\n",
      "Index:  20  & time taken:  5.329355955123901\n",
      "Index:  30  & time taken:  7.973233938217163\n",
      "Index:  40  & time taken:  10.791098833084106\n",
      "Index:  50  & time taken:  13.536258935928345\n",
      "Index:  60  & time taken:  16.281173944473267\n",
      "Index:  70  & time taken:  18.76628875732422\n",
      "Index:  80  & time taken:  21.52734112739563\n",
      "Index:  90  & time taken:  24.169163942337036\n",
      "Index:  100  & time taken:  26.962733030319214\n",
      "0.039603960396039604\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "N = 100\n",
    "knn_clustering(k, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobi Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting distances from the average gallery vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of unique labels in gallery \n",
    "len(np.unique(gallery_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.cov(np.transpose(gallery_images))\n",
    "A = np.linalg.inv(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 2048)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5328, 2048)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_gallery_images = gallery_images.mean(axis=0)     # to take the mean of each column (colummn -> feature)\n",
    "mean_gallery_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_set_distances = [np.sqrt(np.dot(np.dot(np.transpose(query_image-mean_gallery_images),A), query_image-mean_gallery_images))\n",
    "                      for query_image in query_images]\n",
    "np.array(query_set_distances).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting distances using kNN and Mahalanobi Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='mahalanobis',\n",
       "         metric_params={'V': array([[ 0.09833, -0.00735, ..., -0.00826, -0.00833],\n",
       "       [-0.00735,  0.20639, ..., -0.00024, -0.00667],\n",
       "       ...,\n",
       "       [-0.00826, -0.00024, ...,  0.22353,  0.06679],\n",
       "       [-0.00833, -0.00667, ...,  0.06679,  0.10489]])},\n",
       "         n_jobs=1, n_neighbors=100, p=2, radius=1.0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_md = NearestNeighbors(n_neighbors=N,metric='mahalanobis', \n",
    "            metric_params= {'V': np.cov(np.transpose(gallery_images))})\n",
    "neigh_md.fit(gallery_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_mahalanobi(k, N):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()[:300]):\n",
    "        if (index % 50 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh_md.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "        topN_gallery_images = gallery_images[N_indices[0]]\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "        reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(\"Avg Accuracy is: \", acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  8.082389831542969e-05\n",
      "Index:  50  & time taken:  1194.6821658611298\n",
      "Index:  100  & time taken:  2801.5326719284058\n",
      "Index:  150  & time taken:  4013.9011237621307\n",
      "Index:  200  & time taken:  5203.121114730835\n",
      "Index:  250  & time taken:  6391.557485818863\n",
      "Avg Accuracy is:  0.13666666666666666\n",
      "Index:  0  & time taken:  7.224082946777344e-05\n",
      "Index:  50  & time taken:  1187.0171492099762\n",
      "Index:  100  & time taken:  2373.66286110878\n",
      "Index:  150  & time taken:  3560.3639900684357\n",
      "Index:  200  & time taken:  4746.637277126312\n",
      "Index:  250  & time taken:  5932.8617470264435\n",
      "Avg Accuracy is:  0.2833333333333333\n",
      "Index:  0  & time taken:  9.083747863769531e-05\n",
      "Index:  50  & time taken:  1186.3573276996613\n",
      "Index:  100  & time taken:  2372.715752840042\n",
      "Index:  150  & time taken:  3559.498749732971\n",
      "Index:  200  & time taken:  4745.957722663879\n",
      "Index:  250  & time taken:  5932.393654823303\n",
      "Avg Accuracy is:  0.4533333333333333\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "k = [1, 10, 100]\n",
    "acc_k2 = []\n",
    "for k_val in k: \n",
    "    acc = get_accuracy_mahalanobi(k_val, N)\n",
    "    acc_k2.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09090909090909091, 0.18181818181818182, 0.36363636363636365]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13666666666666666, 0.2833333333333333, 0.4533333333333333]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=100, p=2, radius=1.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "neigh_c = NearestNeighbors(n_neighbors=N,metric='cosine')\n",
    "neigh_c.fit(gallery_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  7.700920104980469e-05\n",
      "Index:  50  & time taken:  4.227119207382202\n",
      "Index:  100  & time taken:  8.423174142837524\n",
      "Index:  150  & time taken:  12.630351066589355\n",
      "Index:  200  & time taken:  16.83267116546631\n",
      "Index:  250  & time taken:  21.04805612564087\n",
      "Avg Accuracy is:  0.49\n",
      "Index:  0  & time taken:  5.1975250244140625e-05\n",
      "Index:  50  & time taken:  4.1925787925720215\n",
      "Index:  100  & time taken:  8.413705825805664\n",
      "Index:  150  & time taken:  12.6040678024292\n",
      "Index:  200  & time taken:  16.792085886001587\n",
      "Index:  250  & time taken:  20.98653793334961\n",
      "Avg Accuracy is:  0.74\n",
      "Index:  0  & time taken:  5.3882598876953125e-05\n",
      "Index:  50  & time taken:  4.198216199874878\n",
      "Index:  100  & time taken:  8.467583894729614\n",
      "Index:  150  & time taken:  12.67863917350769\n",
      "Index:  200  & time taken:  16.884459972381592\n",
      "Index:  250  & time taken:  21.093831062316895\n",
      "Avg Accuracy is:  0.91\n"
     ]
    }
   ],
   "source": [
    "def get_acc_gen(k, N, index, query_index):\n",
    "    N_distances, N_indices = neigh_c.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "    topN_gallery_images = gallery_images[N_indices[0]]\n",
    "    forLoopStart = time.time()\n",
    "    topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "    reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "k = [1, 10, 100]\n",
    "acc_k3 = []\n",
    "for k_val in k:\n",
    "    list_of_truths = [] \n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()[:300]):\n",
    "        if (index % 50 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        truth_false = get_acc_gen(k_val, N, index, query_index)\n",
    "        list_of_truths.append(truth_false)\n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(\"Avg Accuracy is: \", acc)\n",
    "    acc_k3.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
