{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern recognition CW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "import metric_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with 6 main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "camId : which camera was used to get the shot (1 or 2)\n",
    "filelist: names of the images (with format x_label_camId_index.png)\n",
    "labels: class of the image (which person's image is it?)\n",
    "query_idx: indexes of test set\n",
    "gallery_idx: indexes of test set used for kNN \n",
    "train_idx: indexes of training and validation set\n",
    "\"\"\"   \n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with the feature vectors of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 2048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "features_np = np.array(features) #list of features converted to an array \n",
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_indices = train_idxs['gallery_idx'].flatten() - 1\n",
    "gallery_images = features_np[gallery_indices]\n",
    "gallery_labels = train_idxs['labels'][gallery_indices]\n",
    "\n",
    "query_indices = train_idxs['query_idx'].flatten() - 1\n",
    "query_images = features_np[query_indices]\n",
    "query_labels = train_idxs['labels'][query_indices]\n",
    "\n",
    "training_indices = train_idxs['train_idx'].flatten() - 1\n",
    "training_images = features_np[training_indices]\n",
    "training_labels = train_idxs['labels'][training_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classification for query set on gallery set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_index(value, recall): #only used in calcAP function below\n",
    "    for index, recall_val in enumerate(recall):\n",
    "        if recall_val >= value:\n",
    "            return index\n",
    "    \n",
    "def calcAP(true_label, rank_k_labels):\n",
    "    correct_list = [true_label == this_label for this_label in rank_k_labels]    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(len(rank_k_labels)):\n",
    "        precision.append(sum(correct_list[:i+1])/len(correct_list[:i+1]))\n",
    "        recall.append(sum(correct_list[:i+1])/sum(correct_list))\n",
    "    max_list = []\n",
    "    for i in range(11):\n",
    "        recall_index = calculate_recall_index(i/10, recall)\n",
    "        max_list.append(max(precision[recall_index:]))\n",
    "    print(max_list)\n",
    "    return np.mean(max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_indices(n_indices, query_index):\n",
    "    query_label_and_camId = (train_idxs['labels'][query_index][0], train_idxs['camId'][query_index][0])\n",
    "    list_of_gallery_label_and_camId = [(label[0], camId[0]) for label, camId in zip(train_idxs['labels'][n_indices], train_idxs['camId'][n_indices])] \n",
    "    final_list = list(filter(lambda a: a != query_label_and_camId, list_of_gallery_label_and_camId))\n",
    "    return [tup[0] for tup in final_list]\n",
    "\n",
    "def get_accuracy(k, N):\n",
    "    list_of_truths = []\n",
    "    AP_vals = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1)\n",
    "    neigh.fit(gallery_images)   #new_gallery_labels)\n",
    "    for index, query_index in enumerate(query_indices.tolist()):\n",
    "        if (index % 100 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh.kneighbors(query_images[index].reshape(1, 2048))\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = (gallery_indices[N_indices[0]]).tolist()\n",
    "        reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "        AP = calcAP(query_labels[index][0], reduced_topN_labels[:k])\n",
    "        AP_vals.append(AP)\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    #print(acc)\n",
    "    return acc, np.mean(AP_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank  1 : \n",
      "Index:  0  & time taken:  0.6711568832397461\n",
      "Index:  100  & time taken:  11.172960996627808\n",
      "Index:  200  & time taken:  21.65892195701599\n",
      "Index:  300  & time taken:  32.16593790054321\n",
      "Index:  400  & time taken:  42.716115951538086\n",
      "Index:  500  & time taken:  53.33190989494324\n",
      "Index:  600  & time taken:  63.814366817474365\n",
      "Index:  700  & time taken:  74.30272483825684\n",
      "Index:  800  & time taken:  84.79265689849854\n",
      "Index:  900  & time taken:  95.2760329246521\n",
      "Index:  1000  & time taken:  105.76963686943054\n",
      "Index:  1100  & time taken:  116.35101675987244\n",
      "Index:  1200  & time taken:  126.84344291687012\n",
      "Index:  1300  & time taken:  137.45032286643982\n",
      "0.47\n",
      "For rank  5 : \n",
      "Index:  0  & time taken:  0.6394927501678467\n",
      "Index:  100  & time taken:  11.25248098373413\n",
      "Index:  200  & time taken:  21.72057294845581\n",
      "Index:  300  & time taken:  32.267863035202026\n",
      "Index:  400  & time taken:  42.73586893081665\n",
      "Index:  500  & time taken:  53.28752779960632\n",
      "Index:  600  & time taken:  63.815351724624634\n",
      "Index:  700  & time taken:  74.4204969406128\n",
      "Index:  800  & time taken:  84.96087288856506\n",
      "Index:  900  & time taken:  95.460453748703\n",
      "Index:  1000  & time taken:  105.97312092781067\n",
      "Index:  1100  & time taken:  116.46223497390747\n",
      "Index:  1200  & time taken:  126.97392106056213\n",
      "Index:  1300  & time taken:  137.47450280189514\n",
      "0.6685714285714286\n",
      "For rank  10 : \n",
      "Index:  0  & time taken:  0.6452178955078125\n",
      "Index:  100  & time taken:  11.109328031539917\n",
      "Index:  200  & time taken:  21.73889708518982\n",
      "Index:  300  & time taken:  32.20466876029968\n",
      "Index:  400  & time taken:  42.78096294403076\n",
      "Index:  500  & time taken:  53.28931188583374\n",
      "Index:  600  & time taken:  63.80353307723999\n",
      "Index:  700  & time taken:  74.29401993751526\n",
      "Index:  800  & time taken:  84.7418520450592\n",
      "Index:  900  & time taken:  95.19498491287231\n",
      "Index:  1000  & time taken:  105.73614311218262\n",
      "Index:  1100  & time taken:  116.32985377311707\n",
      "Index:  1200  & time taken:  126.83406400680542\n",
      "Index:  1300  & time taken:  137.2734079360962\n",
      "0.7492857142857143\n"
     ]
    }
   ],
   "source": [
    "N=100\n",
    "k = [1, 5, 10]\n",
    "results = []\n",
    "for k_val in k: \n",
    "    print(\"For rank \", k_val, \": \")\n",
    "    accuracy, mAP = get_accuracy(k_val, N)\n",
    "    tup = (k_val, accuracy, mAP)\n",
    "    results.append(tup)\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for kNN: \n",
    "\n",
    "k = 1, Accuracy = 0.47\n",
    "k = 5, Accuracy = 0.6685714285714286\n",
    "k = 10, Accuracy = 0.7492857142857143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_indices_in_cluster(c, index_and_cluster): \n",
    "    gallery_indices_in_cluster = [pair[0] for pair in index_and_cluster if pair[1] == c]\n",
    "    return gallery_indices_in_cluster\n",
    "\n",
    "def img_cluster(k, N, c_g_indices, query_index, index):\n",
    "    list_of_truths = []\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(features_np[c_g_indices])   #new_gallery_labels)\n",
    "    N_distances, N_indices = neigh.kneighbors(query_images[index].reshape(1, -1))\n",
    "    topN_c_g_indices = (gallery_indices[N_indices[0]]).tolist()\n",
    "    reduced_topN_labels = remove_indices(topN_c_g_indices, query_index)\n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "def knn_clustering(k, N, index_and_cluster):\n",
    "    class_success = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(query_indices.tolist()[:700]):\n",
    "        if (index % 200 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        cluster = kmeans.predict(query_images[index].reshape(1,-1))\n",
    "        cluster_gallery_indices = img_indices_in_cluster(cluster, index_and_cluster)\n",
    "        class_success.append(img_cluster(k, N, cluster_gallery_indices, query_index, index))\n",
    "    \n",
    "    #over-all accuracy\n",
    "    acc = sum(class_success)/len(class_success)\n",
    "    print(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  4.506111145019531e-05\n",
      "Index:  200  & time taken:  150.7624750137329\n",
      "Index:  400  & time taken:  301.3440308570862\n",
      "Index:  600  & time taken:  461.696977853775\n",
      "0.49714285714285716\n",
      "Index:  0  & time taken:  4.696846008300781e-05\n",
      "Index:  200  & time taken:  156.14981603622437\n",
      "Index:  400  & time taken:  307.5661029815674\n",
      "Index:  600  & time taken:  461.1602611541748\n",
      "0.69\n",
      "Index:  0  & time taken:  5.0067901611328125e-05\n",
      "Index:  200  & time taken:  153.74979496002197\n",
      "Index:  400  & time taken:  308.7922320365906\n",
      "Index:  600  & time taken:  465.1946897506714\n",
      "0.7742857142857142\n",
      "Index:  0  & time taken:  4.792213439941406e-05\n",
      "Index:  200  & time taken:  51.17026996612549\n",
      "Index:  400  & time taken:  104.5521879196167\n",
      "Index:  600  & time taken:  155.86516094207764\n",
      "0.0\n",
      "Index:  0  & time taken:  7.796287536621094e-05\n",
      "Index:  200  & time taken:  51.24071407318115\n",
      "Index:  400  & time taken:  104.89248394966125\n",
      "Index:  600  & time taken:  156.0232548713684\n",
      "0.0014285714285714286\n",
      "Index:  0  & time taken:  7.200241088867188e-05\n",
      "Index:  200  & time taken:  51.43580603599548\n",
      "Index:  400  & time taken:  104.93968510627747\n",
      "Index:  600  & time taken:  156.0580611228943\n",
      "0.005714285714285714\n",
      "Index:  0  & time taken:  4.291534423828125e-05\n",
      "Index:  200  & time taken:  29.55681800842285\n",
      "Index:  400  & time taken:  58.99013090133667\n",
      "Index:  600  & time taken:  87.96334171295166\n",
      "0.0\n",
      "Index:  0  & time taken:  6.914138793945312e-05\n",
      "Index:  200  & time taken:  29.59423804283142\n",
      "Index:  400  & time taken:  59.0254921913147\n",
      "Index:  600  & time taken:  87.95643329620361\n",
      "0.004285714285714286\n",
      "Index:  0  & time taken:  9.584426879882812e-05\n",
      "Index:  200  & time taken:  29.54171586036682\n",
      "Index:  400  & time taken:  58.96396994590759\n",
      "Index:  600  & time taken:  87.91403484344482\n",
      "0.011428571428571429\n"
     ]
    }
   ],
   "source": [
    "total_number_of_labels = len(np.unique(gallery_labels.flatten()))\n",
    "\n",
    "acc_kmeans = []\n",
    "clusters = [1, 3, 10] \n",
    "clusters2 = [100, total_number_of_labels]\n",
    "for n_clusters in clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(gallery_images)\n",
    "    index_and_cluster = [(index, label) for index, label in zip(gallery_indices, kmeans.labels_)]\n",
    "    k = [1, 5, 10]\n",
    "    N = 100\n",
    "    for k_val in k:\n",
    "        acc_kmeans.append(knn_clustering(k_val, N, index_and_cluster)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kmeans2 = []\n",
    "clusters = [100, total_number_of_labels]\n",
    "for n_clusters in clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(gallery_images)\n",
    "    index_and_cluster = [(index, label) for index, label in zip(gallery_indices, kmeans.labels_)]\n",
    "    k = [1, 5, 10]\n",
    "    N = 50\n",
    "    for k_val in k:\n",
    "        acc_kmeans2.append(knn_clustering(k_val, N, index_and_cluster)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobi Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.cov(np.transpose(training_images))\n",
    "A = np.linalg.inv(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up LMNN\n",
    "lmnn = metric_learn.LMNN(k=1)\n",
    "# fit the data!\n",
    "lmnn.fit(training_images, training_labels)\n",
    "# transform our input space\n",
    "A = lmnn.metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  0.0003781318664550781\n",
      "Index:  1  & time taken:  12.34682297706604\n",
      "Index:  2  & time taken:  27.84221315383911\n",
      "Index:  3  & time taken:  43.7835910320282\n",
      "Index:  4  & time taken:  57.16001796722412\n",
      "Index:  5  & time taken:  71.11046099662781\n",
      "Index:  6  & time taken:  85.21257090568542\n",
      "Index:  7  & time taken:  97.4102931022644\n",
      "Index:  8  & time taken:  109.49920701980591\n",
      "Index:  9  & time taken:  121.57118320465088\n",
      "Index:  10  & time taken:  133.7288088798523\n",
      "Index:  11  & time taken:  145.9414541721344\n",
      "Index:  12  & time taken:  158.0778648853302\n",
      "Index:  13  & time taken:  170.14783310890198\n",
      "Index:  14  & time taken:  182.60380911827087\n",
      "Index:  15  & time taken:  194.58802318572998\n",
      "Index:  16  & time taken:  206.63306999206543\n",
      "Index:  17  & time taken:  218.6304099559784\n",
      "Index:  18  & time taken:  230.8930628299713\n",
      "Index:  19  & time taken:  243.50001406669617\n",
      "Index:  20  & time taken:  255.6379430294037\n"
     ]
    }
   ],
   "source": [
    "list_of_truths = []\n",
    "i = 0\n",
    "N = 50\n",
    "k = 1\n",
    "\n",
    "start = time.time() #time tracking - start time of process\n",
    "for q_index, q_image in zip(query_indices, query_images): \n",
    "    print(\"Index: \", i, \" & time taken: \", time.time() - start)\n",
    "    query_distances = []\n",
    "    for g_index, g_image in zip(gallery_indices, gallery_images): \n",
    "        image_diff = q_image - g_image\n",
    "        query_distances.append(tuple([g_index, np.linalg.multi_dot([np.transpose(image_diff), S, image_diff])]))\n",
    "        #query_distances.append(tuple([g_index, np.dot(np.dot(np.transpose(image_diff), S), image_diff)]))\n",
    "    query_distances_sorted = sorted(query_distances,key=lambda x:(x[1]))\n",
    "    N_gallery_indices = [tup[0] for tup in query_distances_sorted][:N]\n",
    "    reduced_N_gallery_labels = remove_indices(N_gallery_indices, q_index)\n",
    "    if query_labels[i][0] in reduced_N_gallery_labels[:k]:\n",
    "        list_of_truths.append(True)\n",
    "    else:\n",
    "        list_of_truths.append(False)\n",
    "        \n",
    "    if i == 20: \n",
    "        break\n",
    "    i +=1\n",
    "acc = sum(list_of_truths)/len(list_of_truths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5328, 2048)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_gallery_images = gallery_images.mean(axis=0)     # to take the mean of each column (colummn -> feature)\n",
    "mean_gallery_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_set_distances = [np.sqrt(np.dot(np.dot(np.transpose(query_image-mean_gallery_images),A), query_image-mean_gallery_images))\n",
    "                      for query_image in query_images]\n",
    "np.array(query_set_distances).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting distances using kNN and Mahalanobi Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='mahalanobis',\n",
       "         metric_params={'V': array([[ 0.12217,  0.00295, ..., -0.00943, -0.01215],\n",
       "       [ 0.00295,  0.23106, ...,  0.00179, -0.01196],\n",
       "       ...,\n",
       "       [-0.00943,  0.00179, ...,  0.32026,  0.09041],\n",
       "       [-0.01215, -0.01196, ...,  0.09041,  0.15056]])},\n",
       "         n_jobs=1, n_neighbors=100, p=2, radius=1.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "neigh_md = NearestNeighbors(n_neighbors=N,metric='mahalanobis', \n",
    "            metric_params= {'V': np.cov(np.transpose(training_images))})\n",
    "neigh_md.fit(gallery_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_mahalanobi(k, N):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()[:300]):\n",
    "        if (index % 50 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh_md.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "        topN_gallery_images = gallery_images[N_indices[0]]\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "        reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(\"Avg Accuracy is: \", acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  8.082389831542969e-05\n",
      "Index:  50  & time taken:  1194.6821658611298\n",
      "Index:  100  & time taken:  2801.5326719284058\n",
      "Index:  150  & time taken:  4013.9011237621307\n",
      "Index:  200  & time taken:  5203.121114730835\n",
      "Index:  250  & time taken:  6391.557485818863\n",
      "Avg Accuracy is:  0.13666666666666666\n",
      "Index:  0  & time taken:  7.224082946777344e-05\n",
      "Index:  50  & time taken:  1187.0171492099762\n",
      "Index:  100  & time taken:  2373.66286110878\n",
      "Index:  150  & time taken:  3560.3639900684357\n",
      "Index:  200  & time taken:  4746.637277126312\n",
      "Index:  250  & time taken:  5932.8617470264435\n",
      "Avg Accuracy is:  0.2833333333333333\n",
      "Index:  0  & time taken:  9.083747863769531e-05\n",
      "Index:  50  & time taken:  1186.3573276996613\n",
      "Index:  100  & time taken:  2372.715752840042\n",
      "Index:  150  & time taken:  3559.498749732971\n",
      "Index:  200  & time taken:  4745.957722663879\n",
      "Index:  250  & time taken:  5932.393654823303\n",
      "Avg Accuracy is:  0.4533333333333333\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "k = [1, 10, 100]\n",
    "acc_k2 = []\n",
    "for k_val in k: \n",
    "    acc = get_accuracy_mahalanobi(k_val, N)\n",
    "    acc_k2.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09090909090909091, 0.18181818181818182, 0.36363636363636365]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13666666666666666, 0.2833333333333333, 0.4533333333333333]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=100, p=2, radius=1.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "neigh_c = NearestNeighbors(n_neighbors=N,metric='cosine')\n",
    "neigh_c.fit(gallery_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  7.700920104980469e-05\n",
      "Index:  50  & time taken:  4.227119207382202\n",
      "Index:  100  & time taken:  8.423174142837524\n",
      "Index:  150  & time taken:  12.630351066589355\n",
      "Index:  200  & time taken:  16.83267116546631\n",
      "Index:  250  & time taken:  21.04805612564087\n",
      "Avg Accuracy is:  0.49\n",
      "Index:  0  & time taken:  5.1975250244140625e-05\n",
      "Index:  50  & time taken:  4.1925787925720215\n",
      "Index:  100  & time taken:  8.413705825805664\n",
      "Index:  150  & time taken:  12.6040678024292\n",
      "Index:  200  & time taken:  16.792085886001587\n",
      "Index:  250  & time taken:  20.98653793334961\n",
      "Avg Accuracy is:  0.74\n",
      "Index:  0  & time taken:  5.3882598876953125e-05\n",
      "Index:  50  & time taken:  4.198216199874878\n",
      "Index:  100  & time taken:  8.467583894729614\n",
      "Index:  150  & time taken:  12.67863917350769\n",
      "Index:  200  & time taken:  16.884459972381592\n",
      "Index:  250  & time taken:  21.093831062316895\n",
      "Avg Accuracy is:  0.91\n"
     ]
    }
   ],
   "source": [
    "def get_acc_gen(k, N, index, query_index):\n",
    "    N_distances, N_indices = neigh_c.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "    topN_gallery_images = gallery_images[N_indices[0]]\n",
    "    forLoopStart = time.time()\n",
    "    topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "    reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "k = [1, 10, 100]\n",
    "acc_k3 = []\n",
    "for k_val in k:\n",
    "    list_of_truths = [] \n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()[:300]):\n",
    "        if (index % 50 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        truth_false = get_acc_gen(k_val, N, index, query_index)\n",
    "        list_of_truths.append(truth_false)\n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(\"Avg Accuracy is: \", acc)\n",
    "    acc_k3.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
