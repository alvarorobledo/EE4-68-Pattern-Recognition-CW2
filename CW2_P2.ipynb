{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern recognition CW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import metric_learn\n",
    "from numpy import linalg as calc_eigen\n",
    "from sklearn.preprocessing import normalize as normalize_vectors\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with 6 main components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "camId : which camera was used to get the shot (1 or 2)\n",
    "filelist: names of the images (with format x_label_camId_index.png)\n",
    "labels: class of the image (which person's image is it?)\n",
    "query_idx: indexes of test set\n",
    "gallery_idx: indexes of test set used for kNN \n",
    "train_idx: indexes of training and validation set\n",
    "\"\"\"   \n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file with the feature vectors of all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 2048)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "features_np = np.array(features) #list of features converted to an array \n",
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_indices = train_idxs['gallery_idx'].flatten() - 1\n",
    "gallery_images = features_np[gallery_indices]\n",
    "gallery_labels = train_idxs['labels'][gallery_indices]\n",
    "\n",
    "query_indices = train_idxs['query_idx'].flatten() - 1\n",
    "query_images = features_np[query_indices]\n",
    "query_labels = train_idxs['labels'][query_indices]\n",
    "\n",
    "training_indices = train_idxs['train_idx'].flatten() - 1\n",
    "training_images = features_np[training_indices]\n",
    "training_labels = train_idxs['labels'][training_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAverageFace(X):\n",
    "    \"\"\"\n",
    "    takes the training data set as input \n",
    "    and returns the average face\n",
    "    \"\"\"\n",
    "    average_face= np.mean(X, axis=0)\n",
    "    #plt.figure()\n",
    "    #plt.title(\"Average Face\")\n",
    "    #plt.imshow(np.resize(average_face, (46, 56)).T, cmap='gray')\n",
    "    return average_face\n",
    "\n",
    "def normalize(X, AvgFace):\n",
    "    \"\"\"\n",
    "    takes the training data set and average face as input \n",
    "    and returns the normalized training data set\n",
    "\n",
    "    \"\"\"\n",
    "    Q = np.empty((len(X[:,0]),len(X[0, :])))\n",
    "    for index, face in enumerate(X):\n",
    "        Q[index] = face - AvgFace\n",
    "    return Q.T\n",
    "\n",
    "def calculateCovarianceMatrix(Q):\n",
    "    return np.matmul(Q,Q.T)/len(Q[0,:])\n",
    "\n",
    "def calculateLowDimCovarianceMatrix(Q):\n",
    "    return np.matmul(Q.T,Q)/len(Q[0,:])\n",
    "\n",
    "def calculateEigenValuesAndVectors(S):\n",
    "    \"\"\"\n",
    "    Takes covariance matrix as input\n",
    "    and returns eigen values and vectors\n",
    "    \"\"\"\n",
    "    v, w =  calc_eigen.eigh(S)\n",
    "    #eigen_vectors[:,i] --> eigen_values[i]\n",
    "    #eigen vector corresponding to eigen value\n",
    "\n",
    "    #flips left to right... ascending to descending\n",
    "    v = np.flip(v, axis=0) #turn ascending into descending\n",
    "    w = np.flip(w, axis=1) #turn ascending into descending\n",
    "    return v, w\n",
    "\n",
    "def calculateWeights(Q, U):\n",
    "    \"\"\"\n",
    "    takes input the normalized input and the eigen space\n",
    "    outputs the weights of the normalized input\n",
    "    \"\"\"\n",
    "    N = len(Q[0,:])\n",
    "    W = np.empty((N,len(U[0, :])))\n",
    "    for index, image in enumerate(Q.T):\n",
    "        W[index] = np.matmul(image, U)\n",
    "    return W\n",
    "\n",
    "def calculateWeights2(Q, U):\n",
    "    \"\"\"\n",
    "    alternative method to calculate weights\n",
    "    \"\"\"\n",
    "    N = len(Q[0,:])\n",
    "    W2 = np.empty((N,len(U[0, :])))\n",
    "    W2 = np.matmul(Q.T, top_eigen_vectors)\n",
    "    return W2\n",
    "\n",
    "def printImage(face, title, saved_file):\n",
    "    \"\"\"\n",
    "    takes input as the face you want to print, the title of the image, and the location of the file\n",
    "    you would like to save the image to. \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(np.resize(face, (46, 56)).T, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(saved_file, bbox_inches='tight')   # save the figure to file\n",
    "    plt.show()\n",
    "    plt.close() \n",
    "    \n",
    "def plotEigenValueGraph(v, points):\n",
    "    \"\"\"\n",
    "    plots eigen values against inrementing the number of eigen values used\n",
    "    in descending order\n",
    "    \"\"\"\n",
    "    y_points = [value for value in v[:points]]\n",
    "    x_points = [i for i in range(points)]\n",
    "    plt.xlabel('Number of Eigen Values')\n",
    "    plt.ylabel('Eigen Values')\n",
    "    plt.title('Plot of Eigen Values in Descending Order')\n",
    "    plt.plot(x_points, y_points)\n",
    "    plt.savefig('eigenvalues.png', bbox_inches='tight')   # save the figure to file\n",
    "    plt.show()\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on Training, Gallery, and Query Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "As described in the documentation, pca.components_ outputs an \n",
    "array of [n_components, n_features], so to get how components \n",
    "are linearly related with the different features you have to:\n",
    "\"\"\"\n",
    "def PCA2(X, M):\n",
    "    # normalize data\n",
    "    #normalized_X = preprocessing.scale(X.T)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=M)\n",
    "    reduced_X = pca.fit_transform(X)\n",
    "    \n",
    "    return reduced_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 1400)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = 2048\n",
    "reduced_training_images = PCA2(training_images, M)\n",
    "reduced_gallery_images = PCA2(gallery_images, M)\n",
    "reduced_query_images = PCA2(query_images, M)\n",
    "reduced_query_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 2048)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X, M):\n",
    "    AvgFace = calculateAverageFace(X)\n",
    "    A = normalize(X, AvgFace)\n",
    "    S = calculateCovarianceMatrix(A)\n",
    "    eigen_values, eigen_vectors = calculateEigenValuesAndVectors(S)\n",
    "    x_points = 1000\n",
    "    #plotEigenValueGraph(eigen_values, x_points)\n",
    "    variance_captured = np.sum(eigen_values[:M])*100/np.sum(eigen_values)\n",
    "    print(\"Variance Captured by top \", x_points, \" features is \", variance_captured, \".\")\n",
    "    top_eigen_vectors = eigen_vectors[:, :M]\n",
    "\n",
    "    reduced_dim_X =  calculateWeights(A, top_eigen_vectors)\n",
    "    return reduced_dim_X, top_eigen_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Captured by top  1000  features is  92.92050565369442 .\n"
     ]
    }
   ],
   "source": [
    "M = 100\n",
    "reduced_training_images, eigen_space = PCA(training_images, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_gallery_images = calculateWeights(normalize(gallery_images, AvgFace), eigen_space)\n",
    "reduced_query_images = calculateWeights(normalize(query_images, AvgFace), eigen_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Classification for query set on gallery set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall_index(value, recall): #only used in calcAP function below\n",
    "    for index, recall_val in enumerate(recall):\n",
    "        if recall_val >= value:\n",
    "            return index\n",
    "    \n",
    "def calcAP(true_label, rank_k_labels):\n",
    "    correct_list = [true_label == this_label for this_label in rank_k_labels]    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    for i in range(len(rank_k_labels)):\n",
    "        precision.append(sum(correct_list[:i+1])/len(correct_list[:i+1]))\n",
    "        recall.append(sum(correct_list[:i+1])/sum(correct_list))\n",
    "    max_list = []\n",
    "    for i in range(11):\n",
    "        recall_index = calculate_recall_index(i/10, recall)\n",
    "        max_list.append(max(precision[recall_index:]))\n",
    "    #print(max_list)\n",
    "    return np.mean(max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_indices(n_indices, query_index):\n",
    "    query_label_and_camId = (train_idxs['labels'][query_index][0], train_idxs['camId'][query_index][0])\n",
    "    list_of_gallery_label_and_camId = [(label[0], camId[0]) for label, camId in zip(train_idxs['labels'][n_indices], train_idxs['camId'][n_indices])] \n",
    "    final_list = list(filter(lambda a: a != query_label_and_camId, list_of_gallery_label_and_camId))\n",
    "    return [tup[0] for tup in final_list]\n",
    "\n",
    "def get_accuracy(k, N):\n",
    "    list_of_truths = []\n",
    "    AP_vals = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1)\n",
    "    neigh.fit(gallery_images)   #new_gallery_labels)\n",
    "    for index, query_index in enumerate(query_indices.tolist()):\n",
    "        if (index % 100 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh.kneighbors(query_images[index].reshape(1, 2048))\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = (gallery_indices[N_indices[0]]).tolist()\n",
    "        reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "        AP = calcAP(query_labels[index][0], reduced_topN_labels[:k])\n",
    "        AP_vals.append(AP)\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    #print(acc)\n",
    "    return acc, np.mean(AP_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank  1 : \n",
      "Index:  0  & time taken:  0.6330201625823975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  100  & time taken:  11.09302806854248\n",
      "Index:  200  & time taken:  21.656609058380127\n",
      "Index:  300  & time taken:  32.17634606361389\n",
      "Index:  400  & time taken:  42.74071907997131\n",
      "Index:  500  & time taken:  53.18624424934387\n",
      "Index:  600  & time taken:  63.734869956970215\n",
      "Index:  700  & time taken:  74.28422927856445\n",
      "Index:  800  & time taken:  84.80377697944641\n",
      "Index:  900  & time taken:  95.39508509635925\n",
      "Index:  1000  & time taken:  106.03644609451294\n",
      "Index:  1100  & time taken:  116.58560514450073\n",
      "Index:  1200  & time taken:  127.08568906784058\n",
      "Index:  1300  & time taken:  137.68114113807678\n",
      "(1, 0.47, 0.47)\n",
      "For rank  5 : \n",
      "Index:  0  & time taken:  0.6057331562042236\n",
      "Index:  100  & time taken:  11.174184083938599\n",
      "Index:  200  & time taken:  21.870043992996216\n",
      "Index:  300  & time taken:  32.56023406982422\n",
      "Index:  400  & time taken:  43.104028940200806\n",
      "Index:  500  & time taken:  53.7527060508728\n",
      "Index:  600  & time taken:  64.34500098228455\n",
      "Index:  700  & time taken:  74.97934126853943\n",
      "Index:  800  & time taken:  85.54107403755188\n",
      "Index:  900  & time taken:  96.17309904098511\n",
      "Index:  1000  & time taken:  106.78644895553589\n",
      "Index:  1100  & time taken:  117.42659306526184\n",
      "Index:  1200  & time taken:  128.05143213272095\n",
      "Index:  1300  & time taken:  138.71504712104797\n",
      "(5, 0.6685714285714286, 0.5272045454545454)\n",
      "For rank  10 : \n",
      "Index:  0  & time taken:  0.6040680408477783\n",
      "Index:  100  & time taken:  11.279120922088623\n",
      "Index:  200  & time taken:  21.997786045074463\n",
      "Index:  300  & time taken:  32.6515588760376\n",
      "Index:  400  & time taken:  43.34866523742676\n",
      "Index:  500  & time taken:  53.998563051223755\n",
      "Index:  600  & time taken:  64.59102010726929\n",
      "Index:  700  & time taken:  75.2099940776825\n",
      "Index:  800  & time taken:  85.9669680595398\n",
      "Index:  900  & time taken:  96.64234399795532\n",
      "Index:  1000  & time taken:  107.31123781204224\n",
      "Index:  1100  & time taken:  118.07735085487366\n",
      "Index:  1200  & time taken:  128.7832808494568\n",
      "Index:  1300  & time taken:  139.54148292541504\n",
      "(10, 0.7492857142857143, 0.5169191146155432)\n"
     ]
    }
   ],
   "source": [
    "N=100\n",
    "k = [1, 5, 10]\n",
    "results = []\n",
    "for k_val in k: \n",
    "    print(\"For rank \", k_val, \": \")\n",
    "    accuracy, mAP = get_accuracy(k_val, N)\n",
    "    tup = (k_val, accuracy, mAP)\n",
    "    results.append(tup)\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for kNN: \n",
    "\n",
    "k = 1, Accuracy = 0.47, mAP = 0.47\n",
    "\n",
    "k = 5, Accuracy = 0.6685714285714286, mAP = 0.5272045454545454\n",
    "\n",
    "k = 10, Accuracy = 0.7492857142857143, mAP = 0.5169191146155432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_pca(k, N):\n",
    "    list_of_truths = []\n",
    "    AP_vals = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1)\n",
    "    neigh.fit(reduced_gallery_images)   #new_gallery_labels)\n",
    "    for index, query_index in enumerate(query_indices.tolist()):\n",
    "        if (index % 200 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh.kneighbors(reduced_query_images[index].reshape(1, len(reduced_query_images[0, :])))\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = (gallery_indices[N_indices[0]]).tolist()\n",
    "        reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "        AP = calcAP(query_labels[index][0], reduced_topN_labels[:k])\n",
    "        AP_vals.append(AP)\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(acc)\n",
    "    return acc, np.mean(AP_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank  1 : \n",
      "Index:  0  & time taken:  0.02941107749938965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  200  & time taken:  21.079618215560913\n",
      "Index:  400  & time taken:  42.17799711227417\n",
      "Index:  600  & time taken:  63.17202019691467\n",
      "Index:  800  & time taken:  84.27191829681396\n",
      "Index:  1000  & time taken:  105.21672511100769\n",
      "Index:  1200  & time taken:  126.23884606361389\n",
      "0.46714285714285714\n",
      "(1, 0.46714285714285714, 0.46714285714285714)\n",
      "For rank  5 : \n",
      "Index:  0  & time taken:  0.013506174087524414\n",
      "Index:  200  & time taken:  20.97689700126648\n",
      "Index:  400  & time taken:  41.993072271347046\n",
      "Index:  600  & time taken:  63.114259004592896\n",
      "Index:  800  & time taken:  84.1421959400177\n",
      "Index:  1000  & time taken:  105.16470098495483\n",
      "Index:  1200  & time taken:  126.25219821929932\n",
      "0.6757142857142857\n",
      "(5, 0.6757142857142857, 0.5285400432900433)\n",
      "For rank  10 : \n",
      "Index:  0  & time taken:  0.013849973678588867\n",
      "Index:  200  & time taken:  21.23994207382202\n",
      "Index:  400  & time taken:  42.65201115608215\n",
      "Index:  600  & time taken:  63.94959092140198\n",
      "Index:  800  & time taken:  85.24179100990295\n",
      "Index:  1000  & time taken:  106.2984139919281\n",
      "Index:  1200  & time taken:  127.38018703460693\n",
      "0.7485714285714286\n",
      "(10, 0.7485714285714286, 0.5152942434549578)\n"
     ]
    }
   ],
   "source": [
    "N=100\n",
    "k = [1, 5, 10]\n",
    "results2 = []\n",
    "for k_val in k: \n",
    "    print(\"For rank \", k_val, \": \")\n",
    "    accuracy, mAP = get_accuracy_pca(k_val, N)\n",
    "    tup = (k_val, accuracy, mAP)\n",
    "    results2.append(tup)\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for kNN using PCA: \n",
    "\n",
    "k = 1, Accuracy = 0.46714285714285714, mAP = 0.46714285714285714\n",
    "\n",
    "k = 5, Accuracy = 0.6757142857142857, mAP = 0.5285400432900433\n",
    "\n",
    "k = 10, Accuracy = 0.7485714285714286, mAP = 0.5152942434549578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_indices_in_cluster(c, index_and_cluster): \n",
    "    gallery_indices_in_cluster = [pair[0] for pair in index_and_cluster if pair[1] == c]\n",
    "    return gallery_indices_in_cluster\n",
    "\n",
    "def img_cluster(k, N, c_g_indices, query_index, index):\n",
    "    list_of_truths = []\n",
    "    neigh = NearestNeighbors(n_neighbors=N, n_jobs=-1, metric='euclidean')\n",
    "    neigh.fit(features_np[c_g_indices])   #new_gallery_labels)\n",
    "    N_distances, N_indices = neigh.kneighbors(query_images[index].reshape(1, -1))\n",
    "    topN_c_g_indices = (gallery_indices[N_indices[0]]).tolist()\n",
    "    reduced_topN_labels = remove_indices(topN_c_g_indices, query_index)\n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "def knn_clustering(k, N, index_and_cluster):\n",
    "    class_success = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(query_indices.tolist()[:700]):\n",
    "        if (index % 200 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        cluster = kmeans.predict(query_images[index].reshape(1,-1))\n",
    "        cluster_gallery_indices = img_indices_in_cluster(cluster, index_and_cluster)\n",
    "        class_success.append(img_cluster(k, N, cluster_gallery_indices, query_index, index))\n",
    "    \n",
    "    #over-all accuracy\n",
    "    acc = sum(class_success)/len(class_success)\n",
    "    print(acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  4.506111145019531e-05\n",
      "Index:  200  & time taken:  150.7624750137329\n",
      "Index:  400  & time taken:  301.3440308570862\n",
      "Index:  600  & time taken:  461.696977853775\n",
      "0.49714285714285716\n",
      "Index:  0  & time taken:  4.696846008300781e-05\n",
      "Index:  200  & time taken:  156.14981603622437\n",
      "Index:  400  & time taken:  307.5661029815674\n",
      "Index:  600  & time taken:  461.1602611541748\n",
      "0.69\n",
      "Index:  0  & time taken:  5.0067901611328125e-05\n",
      "Index:  200  & time taken:  153.74979496002197\n",
      "Index:  400  & time taken:  308.7922320365906\n",
      "Index:  600  & time taken:  465.1946897506714\n",
      "0.7742857142857142\n",
      "Index:  0  & time taken:  4.792213439941406e-05\n",
      "Index:  200  & time taken:  51.17026996612549\n",
      "Index:  400  & time taken:  104.5521879196167\n",
      "Index:  600  & time taken:  155.86516094207764\n",
      "0.0\n",
      "Index:  0  & time taken:  7.796287536621094e-05\n",
      "Index:  200  & time taken:  51.24071407318115\n",
      "Index:  400  & time taken:  104.89248394966125\n",
      "Index:  600  & time taken:  156.0232548713684\n",
      "0.0014285714285714286\n",
      "Index:  0  & time taken:  7.200241088867188e-05\n",
      "Index:  200  & time taken:  51.43580603599548\n",
      "Index:  400  & time taken:  104.93968510627747\n",
      "Index:  600  & time taken:  156.0580611228943\n",
      "0.005714285714285714\n",
      "Index:  0  & time taken:  4.291534423828125e-05\n",
      "Index:  200  & time taken:  29.55681800842285\n",
      "Index:  400  & time taken:  58.99013090133667\n",
      "Index:  600  & time taken:  87.96334171295166\n",
      "0.0\n",
      "Index:  0  & time taken:  6.914138793945312e-05\n",
      "Index:  200  & time taken:  29.59423804283142\n",
      "Index:  400  & time taken:  59.0254921913147\n",
      "Index:  600  & time taken:  87.95643329620361\n",
      "0.004285714285714286\n",
      "Index:  0  & time taken:  9.584426879882812e-05\n",
      "Index:  200  & time taken:  29.54171586036682\n",
      "Index:  400  & time taken:  58.96396994590759\n",
      "Index:  600  & time taken:  87.91403484344482\n",
      "0.011428571428571429\n"
     ]
    }
   ],
   "source": [
    "total_number_of_labels = len(np.unique(gallery_labels.flatten()))\n",
    "\n",
    "acc_kmeans = []\n",
    "clusters = [1, 3, 10] \n",
    "clusters2 = [100, total_number_of_labels]\n",
    "for n_clusters in clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(gallery_images)\n",
    "    index_and_cluster = [(index, label) for index, label in zip(gallery_indices, kmeans.labels_)]\n",
    "    k = [1, 5, 10]\n",
    "    N = 100\n",
    "    for k_val in k:\n",
    "        acc_kmeans.append(knn_clustering(k_val, N, index_and_cluster)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_kmeans2 = []\n",
    "clusters = [100, total_number_of_labels]\n",
    "for n_clusters in clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(gallery_images)\n",
    "    index_and_cluster = [(index, label) for index, label in zip(gallery_indices, kmeans.labels_)]\n",
    "    k = [1, 5, 10]\n",
    "    N = 50\n",
    "    for k_val in k:\n",
    "        acc_kmeans2.append(knn_clustering(k_val, N, index_and_cluster)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobi Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S = np.cov(np.transpose(training_images))\n",
    "#A = np.linalg.inv(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_maha(k, N):   \n",
    "    start = time.time() #time tracking - start time of process\n",
    "    lmnn = metric_learn.LMNN(k=k)\n",
    "    # fit the data!\n",
    "    lmnn.fit(reduced_training_images, training_labels) #reduced_dim_training_images\n",
    "    # transform our input space\n",
    "    A = lmnn.metric()\n",
    "    S = np.linalg.inv(A)\n",
    "\n",
    "    list_of_truths = []\n",
    "    i = 0\n",
    "    AP_vals = []\n",
    "    for q_index, q_image in zip(query_indices, reduced_query_images): \n",
    "        if (i % 100 == 0):\n",
    "            print(\"Index: \", i, \" & time taken: \", time.time() - start)\n",
    "        query_distances = []\n",
    "        for g_index, g_image in zip(gallery_indices, reduced_gallery_images): \n",
    "            image_diff = q_image - g_image\n",
    "            query_distances.append(tuple([g_index, np.linalg.multi_dot([np.transpose(image_diff), S, image_diff])]))\n",
    "            #query_distances.append(tuple([g_index, np.dot(np.dot(np.transpose(image_diff), S), image_diff)]))\n",
    "        query_distances_sorted = sorted(query_distances,key=lambda x:(x[1]))\n",
    "        N_gallery_indices = [tup[0] for tup in query_distances_sorted][:N]\n",
    "        reduced_N_gallery_labels = remove_indices(N_gallery_indices, q_index)\n",
    "        if query_labels[i][0] in reduced_N_gallery_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "        AP = calcAP(query_labels[i][0], reduced_N_gallery_labels[:k])\n",
    "        AP_vals.append(AP)\n",
    "        i +=1\n",
    "    acc = sum(list_of_truths)/len(list_of_truths) \n",
    "    return acc, np.mean(AP_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank  1 : \n",
      "Index:  0  & time taken:  5.427803039550781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  100  & time taken:  13.546617984771729\n",
      "Index:  200  & time taken:  21.883944988250732\n",
      "Index:  300  & time taken:  29.981092929840088\n",
      "Index:  400  & time taken:  38.06189799308777\n",
      "Index:  500  & time taken:  46.22734594345093\n",
      "Index:  600  & time taken:  54.30570983886719\n",
      "Index:  700  & time taken:  62.39797401428223\n",
      "Index:  800  & time taken:  70.60209202766418\n",
      "Index:  900  & time taken:  78.81504797935486\n",
      "Index:  1000  & time taken:  86.92118906974792\n",
      "Index:  1100  & time taken:  96.24939298629761\n",
      "Index:  1200  & time taken:  104.35860800743103\n",
      "Index:  1300  & time taken:  112.7339038848877\n",
      "(1, 0.13, 0.13)\n",
      "For rank  5 : \n",
      "Index:  0  & time taken:  5.489860773086548\n",
      "Index:  100  & time taken:  13.865935802459717\n",
      "Index:  200  & time taken:  22.857558965682983\n",
      "Index:  300  & time taken:  32.80487608909607\n",
      "Index:  400  & time taken:  40.977351903915405\n",
      "Index:  500  & time taken:  49.45302486419678\n",
      "Index:  600  & time taken:  57.52837085723877\n"
     ]
    }
   ],
   "source": [
    "k = [1, 5]\n",
    "N = 50\n",
    "results3 = []\n",
    "for k_val in k: \n",
    "    print(\"For rank \", k_val, \": \")\n",
    "    accuracy, mAP = knn_maha(k_val, N)\n",
    "    tup = (k_val, accuracy, mAP)\n",
    "    results3.append(tup)\n",
    "    print(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007857142857142858, 0.03785714285714286]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5328, 2048)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Normalized training set, \n",
    "k = 1, Accuracy = 0.007857142857142858\n",
    "k = 5, Accuracy = \n",
    "k = 10, Accuracy = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Getting distances using kNN and Mahalanobi Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='mahalanobis',\n",
       "         metric_params={'V': array([[ 0.12217,  0.00295, ..., -0.00943, -0.01215],\n",
       "       [ 0.00295,  0.23106, ...,  0.00179, -0.01196],\n",
       "       ...,\n",
       "       [-0.00943,  0.00179, ...,  0.32026,  0.09041],\n",
       "       [-0.01215, -0.01196, ...,  0.09041,  0.15056]])},\n",
       "         n_jobs=1, n_neighbors=100, p=2, radius=1.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "neigh_md = NearestNeighbors(n_neighbors=N,metric='mahalanobis', \n",
    "            metric_params= {'V': np.cov(np.transpose(training_images))})\n",
    "neigh_md.fit(gallery_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_mahalanobi(k, N):\n",
    "    list_of_truths = []\n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()[:300]):\n",
    "        if (index % 50 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        N_distances, N_indices = neigh_md.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "        topN_gallery_images = gallery_images[N_indices[0]]\n",
    "        forLoopStart = time.time()\n",
    "        topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "        reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "        if query_labels[index][0] in reduced_topN_labels[:k]:\n",
    "            list_of_truths.append(True)\n",
    "        else:\n",
    "            list_of_truths.append(False)\n",
    "    #over-all accuracy  \n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(\"Avg Accuracy is: \", acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  8.082389831542969e-05\n",
      "Index:  50  & time taken:  1194.6821658611298\n",
      "Index:  100  & time taken:  2801.5326719284058\n",
      "Index:  150  & time taken:  4013.9011237621307\n",
      "Index:  200  & time taken:  5203.121114730835\n",
      "Index:  250  & time taken:  6391.557485818863\n",
      "Avg Accuracy is:  0.13666666666666666\n",
      "Index:  0  & time taken:  7.224082946777344e-05\n",
      "Index:  50  & time taken:  1187.0171492099762\n",
      "Index:  100  & time taken:  2373.66286110878\n",
      "Index:  150  & time taken:  3560.3639900684357\n",
      "Index:  200  & time taken:  4746.637277126312\n",
      "Index:  250  & time taken:  5932.8617470264435\n",
      "Avg Accuracy is:  0.2833333333333333\n",
      "Index:  0  & time taken:  9.083747863769531e-05\n",
      "Index:  50  & time taken:  1186.3573276996613\n",
      "Index:  100  & time taken:  2372.715752840042\n",
      "Index:  150  & time taken:  3559.498749732971\n",
      "Index:  200  & time taken:  4745.957722663879\n",
      "Index:  250  & time taken:  5932.393654823303\n",
      "Avg Accuracy is:  0.4533333333333333\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "k = [1, 10, 100]\n",
    "acc_k2 = []\n",
    "for k_val in k: \n",
    "    acc = get_accuracy_mahalanobi(k_val, N)\n",
    "    acc_k2.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09090909090909091, 0.18181818181818182, 0.36363636363636365]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13666666666666666, 0.2833333333333333, 0.4533333333333333]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=100, p=2, radius=1.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "neigh_c = NearestNeighbors(n_neighbors=N,metric='cosine')\n",
    "neigh_c.fit(gallery_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0  & time taken:  7.700920104980469e-05\n",
      "Index:  50  & time taken:  4.227119207382202\n",
      "Index:  100  & time taken:  8.423174142837524\n",
      "Index:  150  & time taken:  12.630351066589355\n",
      "Index:  200  & time taken:  16.83267116546631\n",
      "Index:  250  & time taken:  21.04805612564087\n",
      "Avg Accuracy is:  0.49\n",
      "Index:  0  & time taken:  5.1975250244140625e-05\n",
      "Index:  50  & time taken:  4.1925787925720215\n",
      "Index:  100  & time taken:  8.413705825805664\n",
      "Index:  150  & time taken:  12.6040678024292\n",
      "Index:  200  & time taken:  16.792085886001587\n",
      "Index:  250  & time taken:  20.98653793334961\n",
      "Avg Accuracy is:  0.74\n",
      "Index:  0  & time taken:  5.3882598876953125e-05\n",
      "Index:  50  & time taken:  4.198216199874878\n",
      "Index:  100  & time taken:  8.467583894729614\n",
      "Index:  150  & time taken:  12.67863917350769\n",
      "Index:  200  & time taken:  16.884459972381592\n",
      "Index:  250  & time taken:  21.093831062316895\n",
      "Avg Accuracy is:  0.91\n"
     ]
    }
   ],
   "source": [
    "def get_acc_gen(k, N, index, query_index):\n",
    "    N_distances, N_indices = neigh_c.kneighbors(query_images[index].reshape(1, 2048), N)\n",
    "    topN_gallery_images = gallery_images[N_indices[0]]\n",
    "    forLoopStart = time.time()\n",
    "    topN_gallery_indices = train_idxs['gallery_idx'][N_indices[0]].flatten().tolist()\n",
    "    reduced_topN_indices, reduced_topN_labels = remove_indices(topN_gallery_indices, query_index)\n",
    "    return (query_labels[index][0] in reduced_topN_labels[:k])\n",
    "\n",
    "k = [1, 10, 100]\n",
    "acc_k3 = []\n",
    "for k_val in k:\n",
    "    list_of_truths = [] \n",
    "    start = time.time() #time tracking - start time of process\n",
    "    for index, query_index in enumerate(train_idxs['query_idx'].flatten().tolist()[:300]):\n",
    "        if (index % 50 == 0):\n",
    "            print(\"Index: \", index, \" & time taken: \", time.time() - start)\n",
    "        truth_false = get_acc_gen(k_val, N, index, query_index)\n",
    "        list_of_truths.append(truth_false)\n",
    "    acc = sum(list_of_truths)/len(list_of_truths)\n",
    "    print(\"Avg Accuracy is: \", acc)\n",
    "    acc_k3.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
