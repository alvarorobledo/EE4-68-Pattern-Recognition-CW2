{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import metric_learn\n",
    "from numpy import linalg as calc_eigen\n",
    "from sklearn.preprocessing import normalize as normalize_vectors\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.optimize import fmin_slsqp\n",
    "from scipy.optimize import minimize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "camId : which camera was used to get the shot (1 or 2)\n",
    "filelist: names of the images (with format x_label_camId_index.png)\n",
    "labels: class of the image (which person's image is it?)\n",
    "query_idx: indexes of test set\n",
    "gallery_idx: indexes of test set used for kNN \n",
    "train_idx: indexes of training and validation set\n",
    "\"\"\"   \n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14096, 2048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('PR_data/feature_data.json', 'r') as f:\n",
    "    features = json.load(f)\n",
    "features_np = np.array(features) #list of features converted to an array \n",
    "features_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_indices = train_idxs['gallery_idx'].flatten() - 1\n",
    "gallery_images = features_np[gallery_indices]\n",
    "gallery_labels = train_idxs['labels'][gallery_indices]\n",
    "\n",
    "query_indices = train_idxs['query_idx'].flatten() - 1\n",
    "query_images = features_np[query_indices]\n",
    "query_labels = train_idxs['labels'][query_indices]\n",
    "\n",
    "training_indices = train_idxs['train_idx'].flatten() - 1\n",
    "training_images = features_np[training_indices]\n",
    "training_labels = train_idxs['labels'][training_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAverageFace(X):\n",
    "    \"\"\"\n",
    "    takes the training data set as input \n",
    "    and returns the average face\n",
    "    \"\"\"\n",
    "    average_face= np.mean(X, axis=0)\n",
    "    #plt.figure()\n",
    "    #plt.title(\"Average Face\")\n",
    "    #plt.imshow(np.resize(average_face, (46, 56)).T, cmap='gray')\n",
    "    return average_face\n",
    "\n",
    "def normalize(X, AvgFace):\n",
    "    \"\"\"\n",
    "    takes the training data set and average face as input \n",
    "    and returns the normalized training data set\n",
    "\n",
    "    \"\"\"\n",
    "    Q = np.empty((len(X[:,0]),len(X[0, :])))\n",
    "    for index, face in enumerate(X):\n",
    "        Q[index] = face - AvgFace\n",
    "    return Q.T\n",
    "\n",
    "def calculateCovarianceMatrix(Q):\n",
    "    return np.matmul(Q,Q.T)/len(Q[0,:])\n",
    "\n",
    "def calculateLowDimCovarianceMatrix(Q):\n",
    "    return np.matmul(Q.T,Q)/len(Q[0,:])\n",
    "\n",
    "def calculateEigenValuesAndVectors(S):\n",
    "    \"\"\"\n",
    "    Takes covariance matrix as input\n",
    "    and returns eigen values and vectors\n",
    "    \"\"\"\n",
    "    v, w =  calc_eigen.eigh(S)\n",
    "    #eigen_vectors[:,i] --> eigen_values[i]\n",
    "    #eigen vector corresponding to eigen value\n",
    "\n",
    "    #flips left to right... ascending to descending\n",
    "    v = np.flip(v, axis=0) #turn ascending into descending\n",
    "    w = np.flip(w, axis=1) #turn ascending into descending\n",
    "    return v, w\n",
    "\n",
    "def calculateWeights(Q, U):\n",
    "    \"\"\"\n",
    "    takes input the normalized input and the eigen space\n",
    "    outputs the weights of the normalized input\n",
    "    \"\"\"\n",
    "    N = len(Q[0,:])\n",
    "    W = np.empty((N,len(U[0, :])))\n",
    "    for index, image in enumerate(Q.T):\n",
    "        W[index] = np.matmul(image, U)\n",
    "    return W\n",
    "\n",
    "def calculateWeights2(Q, U):\n",
    "    \"\"\"\n",
    "    alternative method to calculate weights\n",
    "    \"\"\"\n",
    "    N = len(Q[0,:])\n",
    "    W2 = np.empty((N,len(U[0, :])))\n",
    "    W2 = np.matmul(Q.T, top_eigen_vectors)\n",
    "    return W2\n",
    "\n",
    "def printImage(face, title, saved_file):\n",
    "    \"\"\"\n",
    "    takes input as the face you want to print, the title of the image, and the location of the file\n",
    "    you would like to save the image to. \n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(np.resize(face, (46, 56)).T, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(saved_file, bbox_inches='tight')   # save the figure to file\n",
    "    plt.show()\n",
    "    plt.close() \n",
    "    \n",
    "def plotEigenValueGraph(v, points):\n",
    "    \"\"\"\n",
    "    plots eigen values against inrementing the number of eigen values used\n",
    "    in descending order\n",
    "    \"\"\"\n",
    "    y_points = [value for value in v[:points]]\n",
    "    x_points = [i for i in range(points)]\n",
    "    plt.xlabel('Number of Eigen Values')\n",
    "    plt.ylabel('Eigen Values')\n",
    "    plt.title('Plot of Eigen Values in Descending Order')\n",
    "    plt.plot(x_points, y_points)\n",
    "    plt.savefig('eigenvalues.png', bbox_inches='tight')   # save the figure to file\n",
    "    plt.show()\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(X, M):\n",
    "    AvgFace = calculateAverageFace(X)\n",
    "    A = normalize(X, AvgFace)\n",
    "    S = calculateCovarianceMatrix(A)\n",
    "    eigen_values, eigen_vectors = calculateEigenValuesAndVectors(S)\n",
    "    x_points = 1000\n",
    "    #plotEigenValueGraph(eigen_values, x_points)\n",
    "    variance_captured = np.sum(eigen_values[:M])*100/np.sum(eigen_values)\n",
    "    print(\"Variance Captured by top \", x_points, \" features is \", variance_captured, \".\")\n",
    "    top_eigen_vectors = eigen_vectors[:, :M]\n",
    "    reduced_dim_X =  calculateWeights(A, top_eigen_vectors)\n",
    "    return reduced_dim_X, top_eigen_vectors, AvgFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Captured by top  1000  features is  92.92050565369442 .\n"
     ]
    }
   ],
   "source": [
    "M = 100\n",
    "reduced_training_images, eigen_space, AvgFace = PCA(training_images, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_gallery_images = calculateWeights(normalize(gallery_images, AvgFace), eigen_space)\n",
    "reduced_query_images = calculateWeights(normalize(query_images, AvgFace), eigen_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_y(X, Y, X_labels, Y_labels):\n",
    "    y = np.zeros((len(X[:, 0]), len(Y[:, 0])),dtype=object) \n",
    "    for t1_index, t1_image in enumerate(X):\n",
    "        for t2_index, t2_image in enumerate(Y):\n",
    "            if X_labels[t1_index] == Y_labels[t2_index]: \n",
    "                y[t1_index][t2_index] = 1\n",
    "            else:\n",
    "                y[t1_index][t2_index] = 0\n",
    "    return y\n",
    "\n",
    "def loss_function_training(A):\n",
    "    distance_matrix_training = cdist(reduced_training_images, reduced_training_images, 'mahalanobis', VI=A)   \n",
    "    agg_dist = sum([np.dot(y_train[i, :],distance_matrix_training.T[:, i]) for i in range(len(training_labels))])\n",
    "    return agg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = calculate_y(reduced_training_images, reduced_training_images, training_labels, training_labels)\n",
    "A0 = np.linalg.inv(np.cov(np.transpose(reduced_training_images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization of Frobenius Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function1(A):\n",
    "    return  math.sqrt(np.sum(A**2))\n",
    "\n",
    "optimization_learning = minimize(loss_function1, A0, method = 'SLSQP')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimization_learning' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f20073d7f3ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimization_learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'optimization_learning' is not defined"
     ]
    }
   ],
   "source": [
    "optimization_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization of LogDet Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function2(A):\n",
    "    return  math.sqrt(np.sum(A**2))\n",
    "    distance = trace(x*np.linalg.inv(y)) - logdet(x**np.linalg.inv(y)) - cdist(x, y, 'mahalanobis', VI=A)\n",
    "\n",
    "optimization_learning = minimize_scalar(loss_function2, A0, method= 'SLSQP') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.optimize.minimize(fun, x0, args=(), method='CG', jac=None, tol=None, callback=None, options={'eps': 1.4901161193847656e-08, 'maxiter': 1, 'disp': True, 'return_all': False}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
